{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semesterarbeit Datenvisualisierung\n",
    "Aufbereitung und Erarbeitung der nötigen Daten erfolgen in diesem Jupyternotebook. Anhand von diesen Datenquellen, welche ich in Python Pandas Datenframes lade, enstehen unter anderem Plotly-Grafiken. Diese Grafiken nutze ich für:\n",
    "\n",
    "   - Präsentation innerhalb von dem ``Storytelling-Tool: http://prezi.com``\n",
    "   - ``Shiny for Python Dashboard`` (kann anhand diesem Notebook selbständig getestet werden)\n",
    "\n",
    "Mit dieser Grundlage erstelle ich die Semesterarbeit für die Datenvisualisierung. Für den Statistikteil werde ich einen komplett neuen Datensatz (WORLD VALUES SURVEY WAVE 7, 2017-2021) verwenden um die nötigen 4 Verfahren anzuwenden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quellen: Our World in Data (OWID)\n",
    "https://docs.owid.io/projects/etl/api/#owid-catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspiration und Durchsicht möglicher Quellen\n",
    "* **Datapoints used to train:** https://ourworldindata.org/grapher/artificial-intelligence-number-training-datapoints\n",
    "----\n",
    "* **Annual patent applications (not detailed on technology):** https://ourworldindata.org/grapher/annual-patent-applications\n",
    "* **Annual granted patents related to AI:** https://ourworldindata.org/grapher/artificial-intelligence-granted-patents-by-industry\n",
    "* **Annual working hours:** https://ourworldindata.org/grapher/annual-working-hours-per-worker\n",
    "* **Annual articles publ in scientific and tech journals:** https://ourworldindata.org/grapher/scientific-publications-per-million\n",
    "* **Research and development spending as a share of GDP:** https://ourworldindata.org/grapher/research-spending-gdp\n",
    "* **Research and development per million people vs. GPD per capita:** https://ourworldindata.org/grapher/researchers-in-rd-per-million-people-vs-gdp-pc\n",
    "----\n",
    "* **Population:** https://ourworldindata.org/grapher/population\n",
    "* **Population with UN projections 2100:** https://ourworldindata.org/grapher/population-with-un-projections\n",
    "* **Median age:** https://ourworldindata.org/grapher/median-age\n",
    "* **Female Popl by Age** https://ourworldindata.org/grapher/female-population-by-age-group\n",
    "* **Male Popl by Age** https://ourworldindata.org/grapher/male-population-by-age-group\n",
    "* **Popl young, working, elderly** https://ourworldindata.org/grapher/population-young-working-elderly-with-projections\n",
    "----\n",
    "* **Fertility rate:** https://ourworldindata.org/grapher/children-per-woman-un\n",
    "* **Population by age group:** https://ourworldindata.org/grapher/population-by-age-group-with-projections\n",
    "* **Age dependency breakdown by young and old:** https://ourworldindata.org/grapher/age-dependency-breakdown\n",
    "----\n",
    "* **Public health expenditure as a share of GDP:** https://ourworldindata.org/grapher/public-health-expenditure-share-gdp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datensatzbildung\n",
    "\n",
    "**Technonoligsche Indikatoren**\n",
    "   - https://ourworldindata.org/grapher/artificial-intelligence-granted-patents-by-industry\n",
    "   - https://ourworldindata.org/grapher/research-spending-gdp\n",
    "   - https://ourworldindata.org/grapher/artificial-intelligence-number-training-datapoints\n",
    "\n",
    "**Gesundheitsausgaben**\n",
    "   - https://ourworldindata.org/grapher/public-health-expenditure-share-gdp\n",
    "\n",
    "**Demografische Daten**\n",
    "   - https://ourworldindata.org/grapher/median-age\n",
    "   - https://ourworldindata.org/grapher/age-dependency-breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "from owid.catalog import charts\n",
    "import pandas as pd\n",
    "\n",
    "# Technologische Indikatoren\n",
    "ai_patents_df = charts.get_data('artificial-intelligence-granted-patents-by-industry')\n",
    "rd_gdp_df = charts.get_data('research-spending-gdp')\n",
    "ai_training_df = charts.get_data('artificial-intelligence-number-training-datapoints')\n",
    "\n",
    "# Gesundheitsausgaben\n",
    "health_df = charts.get_data('public-health-expenditure-share-gdp')\n",
    "\n",
    "# Demografische Daten\n",
    "median_age_df = charts.get_data('median-age')\n",
    "dependency_df = charts.get_data('age-dependency-breakdown')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entities</th>\n",
       "      <th>years</th>\n",
       "      <th>num_patent_granted__field_life_sciences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>2013</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>World</td>\n",
       "      <td>2019</td>\n",
       "      <td>4140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>World</td>\n",
       "      <td>2020</td>\n",
       "      <td>4036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>World</td>\n",
       "      <td>2021</td>\n",
       "      <td>3180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>World</td>\n",
       "      <td>2022</td>\n",
       "      <td>1182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>World</td>\n",
       "      <td>2023</td>\n",
       "      <td>355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>421 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      entities  years  num_patent_granted__field_life_sciences\n",
       "0    Argentina   2013                                        0\n",
       "1    Argentina   2017                                        0\n",
       "2    Argentina   2018                                        1\n",
       "3    Argentina   2019                                        1\n",
       "4    Argentina   2020                                        0\n",
       "..         ...    ...                                      ...\n",
       "416      World   2019                                     4140\n",
       "417      World   2020                                     4036\n",
       "418      World   2021                                     3180\n",
       "419      World   2022                                     1182\n",
       "420      World   2023                                      355\n",
       "\n",
       "[421 rows x 3 columns]"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# kurzer Einblick in die Datensätze\n",
    "ai_patents_df = ai_patents_df[['entities', 'years', 'num_patent_granted__field_life_sciences']]\n",
    "ai_patents_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['Argentina', 'Australia', 'Austria', 'Belgium', 'Brazil', 'Brunei',\n",
       "        'Bulgaria', 'Canada', 'Chile', 'China', 'Colombia', 'Croatia',\n",
       "        'Czechia', 'Denmark', 'Estonia', 'Finland', 'France', 'Germany',\n",
       "        'Greece', 'Hong Kong', 'Hungary', 'India', 'Indonesia', 'Iran',\n",
       "        'Ireland', 'Israel', 'Italy', 'Japan', 'Jordan', 'Kenya', 'Latvia',\n",
       "        'Lithuania', 'Luxembourg', 'Malaysia', 'Mexico', 'Morocco',\n",
       "        'Netherlands', 'New Zealand', 'Norway', 'Peru', 'Philippines',\n",
       "        'Poland', 'Portugal', 'Romania', 'Russia', 'Serbia', 'Singapore',\n",
       "        'Slovakia', 'Slovenia', 'South Africa', 'South Korea', 'Spain',\n",
       "        'Sri Lanka', 'Sweden', 'Switzerland', 'Taiwan', 'Turkey',\n",
       "        'Ukraine', 'United Kingdom', 'United States', 'Uruguay', 'World'],\n",
       "       dtype=object),\n",
       " array([2013, 2017, 2018, 2019, 2020, 2014, 2015, 2016, 2021, 2022, 2023]))"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entities und Years untersuchen\n",
    "ai_patents_df['entities'].unique(), ai_patents_df['years'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entities</th>\n",
       "      <th>years</th>\n",
       "      <th>research_spending_gdp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Albania</td>\n",
       "      <td>2007</td>\n",
       "      <td>0.08757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>2008</td>\n",
       "      <td>0.15412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>2001</td>\n",
       "      <td>0.23028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>2002</td>\n",
       "      <td>0.36640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>2003</td>\n",
       "      <td>0.19623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2531</th>\n",
       "      <td>Zambia</td>\n",
       "      <td>2002</td>\n",
       "      <td>0.00544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2532</th>\n",
       "      <td>Zambia</td>\n",
       "      <td>2003</td>\n",
       "      <td>0.00847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2533</th>\n",
       "      <td>Zambia</td>\n",
       "      <td>2004</td>\n",
       "      <td>0.02223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2534</th>\n",
       "      <td>Zambia</td>\n",
       "      <td>2005</td>\n",
       "      <td>0.02493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2535</th>\n",
       "      <td>Zambia</td>\n",
       "      <td>2008</td>\n",
       "      <td>0.27819</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2536 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     entities  years  research_spending_gdp\n",
       "0     Albania   2007                0.08757\n",
       "1     Albania   2008                0.15412\n",
       "2     Algeria   2001                0.23028\n",
       "3     Algeria   2002                0.36640\n",
       "4     Algeria   2003                0.19623\n",
       "...       ...    ...                    ...\n",
       "2531   Zambia   2002                0.00544\n",
       "2532   Zambia   2003                0.00847\n",
       "2533   Zambia   2004                0.02223\n",
       "2534   Zambia   2005                0.02493\n",
       "2535   Zambia   2008                0.27819\n",
       "\n",
       "[2536 rows x 3 columns]"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bereits mehr Records durch die Unterschiede in Entities und Years\n",
    "rd_gdp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['Albania', 'Algeria', 'American Samoa', 'Angola', 'Argentina',\n",
       "        'Armenia', 'Australia', 'Austria', 'Azerbaijan', 'Bahrain',\n",
       "        'Belarus', 'Belgium', 'Bermuda', 'Bolivia',\n",
       "        'Bosnia and Herzegovina', 'Botswana', 'Brazil', 'Brunei',\n",
       "        'Bulgaria', 'Burkina Faso', 'Burundi', 'Cambodia', 'Canada',\n",
       "        'Cape Verde', 'Chad', 'Chile', 'China', 'Colombia', 'Congo',\n",
       "        'Costa Rica', \"Cote d'Ivoire\", 'Croatia', 'Cuba', 'Cyprus',\n",
       "        'Czechia', 'Democratic Republic of Congo', 'Denmark',\n",
       "        'East Asia and Pacific (WB)', 'Ecuador', 'Egypt', 'El Salvador',\n",
       "        'Estonia', 'Eswatini', 'Ethiopia', 'Europe and Central Asia (WB)',\n",
       "        'European Union (27)', 'Faeroe Islands', 'Finland', 'France',\n",
       "        'Gabon', 'Gambia', 'Georgia', 'Germany', 'Ghana', 'Greece',\n",
       "        'Greenland', 'Guam', 'Guatemala', 'High-income countries',\n",
       "        'Honduras', 'Hong Kong', 'Hungary', 'Iceland', 'India',\n",
       "        'Indonesia', 'Iran', 'Iraq', 'Ireland', 'Israel', 'Italy',\n",
       "        'Jamaica', 'Japan', 'Jordan', 'Kazakhstan', 'Kenya', 'Kuwait',\n",
       "        'Kyrgyzstan', 'Laos', 'Latin America and Caribbean (WB)', 'Latvia',\n",
       "        'Lesotho', 'Lithuania', 'Lower-middle-income countries',\n",
       "        'Luxembourg', 'Macao', 'Madagascar', 'Malaysia', 'Mali', 'Malta',\n",
       "        'Mauritania', 'Mauritius', 'Mexico',\n",
       "        'Middle East and North Africa (WB)', 'Middle-income countries',\n",
       "        'Moldova', 'Monaco', 'Mongolia', 'Montenegro', 'Morocco',\n",
       "        'Mozambique', 'Myanmar', 'Namibia', 'Nepal', 'Netherlands',\n",
       "        'New Zealand', 'Nicaragua', 'Nigeria', 'North America (WB)',\n",
       "        'North Macedonia', 'Norway', 'Oman', 'Pakistan', 'Palestine',\n",
       "        'Panama', 'Papua New Guinea', 'Paraguay', 'Peru', 'Philippines',\n",
       "        'Poland', 'Portugal', 'Puerto Rico', 'Qatar', 'Romania', 'Russia',\n",
       "        'Rwanda', 'Saint Lucia', 'Saint Vincent and the Grenadines',\n",
       "        'Saudi Arabia', 'Senegal', 'Serbia', 'Seychelles', 'Singapore',\n",
       "        'Slovakia', 'Slovenia', 'South Africa', 'South Asia (WB)',\n",
       "        'South Korea', 'Spain', 'Sri Lanka', 'Sub-Saharan Africa (WB)',\n",
       "        'Sudan', 'Sweden', 'Switzerland', 'Syria', 'Tajikistan',\n",
       "        'Tanzania', 'Thailand', 'Togo', 'Trinidad and Tobago', 'Tunisia',\n",
       "        'Turkey', 'Uganda', 'Ukraine', 'United Arab Emirates',\n",
       "        'United Kingdom', 'United States', 'United States Virgin Islands',\n",
       "        'Upper-middle-income countries', 'Uruguay', 'Uzbekistan',\n",
       "        'Venezuela', 'Vietnam', 'World', 'Zambia'], dtype=object),\n",
       " array([2007, 2008, 2001, 2002, 2003, 2004, 2005, 2017, 2006, 2016, 1996,\n",
       "        1997, 1998, 1999, 2000, 2009, 2010, 2011, 2012, 2013, 2014, 2015,\n",
       "        2018, 2019, 2020, 2021, 2022]))"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entities und Years untersuchen (bereits ersichtlich die Unterschiede in Jahren und Entities)\n",
    "rd_gdp_df['entities'].unique(), rd_gdp_df['years'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entities</th>\n",
       "      <th>years</th>\n",
       "      <th>research_spending_gdp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.478130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Armenia</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.178540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Australia</td>\n",
       "      <td>2019</td>\n",
       "      <td>1.828920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Austria</td>\n",
       "      <td>2019</td>\n",
       "      <td>3.132470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>Azerbaijan</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.200130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2435</th>\n",
       "      <td>Upper-middle-income countries</td>\n",
       "      <td>2019</td>\n",
       "      <td>1.664090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2458</th>\n",
       "      <td>Uruguay</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.426670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2480</th>\n",
       "      <td>Uzbekistan</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.113060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2501</th>\n",
       "      <td>Vietnam</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.416520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2526</th>\n",
       "      <td>World</td>\n",
       "      <td>2019</td>\n",
       "      <td>2.300463</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>104 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           entities  years  research_spending_gdp\n",
       "36                        Argentina   2019               0.478130\n",
       "61                          Armenia   2019               0.178540\n",
       "77                        Australia   2019               1.828920\n",
       "101                         Austria   2019               3.132470\n",
       "127                      Azerbaijan   2019               0.200130\n",
       "...                             ...    ...                    ...\n",
       "2435  Upper-middle-income countries   2019               1.664090\n",
       "2458                        Uruguay   2019               0.426670\n",
       "2480                     Uzbekistan   2019               0.113060\n",
       "2501                        Vietnam   2019               0.416520\n",
       "2526                          World   2019               2.300463\n",
       "\n",
       "[104 rows x 3 columns]"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = rd_gdp_df[rd_gdp_df['years'] == 2019]\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entities</th>\n",
       "      <th>dates</th>\n",
       "      <th>training_dataset_size__datapoints</th>\n",
       "      <th>domain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(ensemble): AWD-LSTM-DOC (fin) × 5 (WT2)</td>\n",
       "      <td>2018-08-30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2-layer-LSTM+Deep-Gradient-Compression</td>\n",
       "      <td>2017-12-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3D city reconstruction</td>\n",
       "      <td>2009-09-29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4 layer QRNN (h=2500)</td>\n",
       "      <td>2018-03-22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6-Act Tether</td>\n",
       "      <td>2021-08-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>o1-preview</td>\n",
       "      <td>2024-09-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Multiple domains</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>top-down frozen classifier</td>\n",
       "      <td>2021-02-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Speech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929</th>\n",
       "      <td>wave2vec 2.0 LARGE</td>\n",
       "      <td>2020-10-22</td>\n",
       "      <td>727776000.0</td>\n",
       "      <td>Speech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>xTrimoPGLM -100B</td>\n",
       "      <td>2023-07-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Biology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>λ-WASP</td>\n",
       "      <td>2007-06-01</td>\n",
       "      <td>792.0</td>\n",
       "      <td>Language</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>932 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     entities      dates  \\\n",
       "0    (ensemble): AWD-LSTM-DOC (fin) × 5 (WT2) 2018-08-30   \n",
       "1      2-layer-LSTM+Deep-Gradient-Compression 2017-12-05   \n",
       "2                      3D city reconstruction 2009-09-29   \n",
       "3                       4 layer QRNN (h=2500) 2018-03-22   \n",
       "4                                6-Act Tether 2021-08-03   \n",
       "..                                        ...        ...   \n",
       "927                                o1-preview 2024-09-12   \n",
       "928                top-down frozen classifier 2021-02-09   \n",
       "929                        wave2vec 2.0 LARGE 2020-10-22   \n",
       "930                          xTrimoPGLM -100B 2023-07-06   \n",
       "931                                    λ-WASP 2007-06-01   \n",
       "\n",
       "     training_dataset_size__datapoints            domain  \n",
       "0                                  NaN          Language  \n",
       "1                                  NaN          Language  \n",
       "2                                  NaN             Other  \n",
       "3                                  NaN          Language  \n",
       "4                                  NaN             Other  \n",
       "..                                 ...               ...  \n",
       "927                                NaN  Multiple domains  \n",
       "928                                NaN            Speech  \n",
       "929                        727776000.0            Speech  \n",
       "930                                NaN           Biology  \n",
       "931                              792.0          Language  \n",
       "\n",
       "[932 rows x 4 columns]"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# komplett anderer Datensatz (Entities sind keine Länder, sondern ai_systeme, und anstatt Years exisitiert ein Datum usw.). Anzahl der Records: 932\n",
    "ai_training_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['(ensemble): AWD-LSTM-DOC (fin) × 5 (WT2)',\n",
       "       '2-layer-LSTM+Deep-Gradient-Compression', '3D city reconstruction',\n",
       "       '4 layer QRNN (h=2500)', '6-Act Tether', '6-layer MLP (MNIST)',\n",
       "       'A3C FF hs', 'ADALINE', 'ADAM (CIFAR-10)', 'ADAPTIVE NLPM', 'ADM',\n",
       "       'AFM-on-device', 'AFM-server', 'ALBERT', 'ALBERT-xxlarge', 'ALIGN',\n",
       "       'ALM 1.0', 'ALVINN', 'AMDIM', 'ANN Eye Tracker', 'AR-LDM',\n",
       "       'ASE+ACE', 'ATLAS', 'AWD-LSTM',\n",
       "       'AWD-LSTM + MoS + Partial Shuffled',\n",
       "       'AWD-LSTM - 3-layer LSTM (tied) + continuous cache pointer (WT2)',\n",
       "       'AWD-LSTM+WT+Cache+IOG (WT2)',\n",
       "       'AWD-LSTM-DRILL + dynamic evaluation† (WT2)',\n",
       "       'AWD-LSTM-MoS + dynamic evaluation (WT2, 2017)',\n",
       "       'AWD-LSTM-MoS + dynamic evaluation (WT2, 2018)',\n",
       "       'AWD-LSTM-MoS+PDR + dynamic evaluation (WT2)',\n",
       "       'AbLang (heavy sequences)', 'AdaBoost.M2 Digit Recognition',\n",
       "       'AdaRNN', 'Adaptive Input Transformer + RD',\n",
       "       'Adaptive Inputs + LayerDrop', 'Adaptive Subgrad',\n",
       "       'Advantage Learning',\n",
       "       'Adversarial Joint Adaptation Network (ResNet)', 'Agent57',\n",
       "       'Agile Soccer Robot', 'AlexNet', 'AlexaTM 20B', 'AlphaCode',\n",
       "       'AlphaFold', 'AlphaFold 2', 'AlphaFold-Multimer', 'AlphaGeometry',\n",
       "       'AlphaGo Fan', 'AlphaGo Lee', 'AlphaGo Master', 'AlphaGo Zero',\n",
       "       'AlphaMissense', 'AlphaStar', 'AlphaX-1', 'AlphaZero',\n",
       "       'AltCLIP_M9', 'Amazon Nova Pro', 'Amazon Titan',\n",
       "       'AmoebaNet-A (F=190)', 'AmoebaNet-A (F=448)', 'Ankh_large',\n",
       "       'Aramco Metabrain AI', 'AudioGen', 'AudioLM', 'Aya', 'BART-large',\n",
       "       'BASIC-L', 'BASIC-L + Lion', 'BEIT-3', 'BERT-Large',\n",
       "       'BERT-Large-CAS (PTB+WT2+WT103)', 'BERT-RBP', 'BIDAF',\n",
       "       'BLIP-2 (Q-Former)', 'BLOOM-176B', 'BLOOMZ-176B',\n",
       "       'BLSTM for handwriting (1)', 'BLSTM for handwriting (2)', 'BLUUMI',\n",
       "       'BOXES', 'BPE', 'BPL', 'Back-propagation', 'Bankruptcy-NN',\n",
       "       'Base LM + kNN LM + Continuous Cache', 'BatchNorm',\n",
       "       'Bayesian automated hyperparameter tuning', 'BellKor 2007',\n",
       "       'BellKor 2008', 'BellKor 2009', 'BiLSTM for Speech',\n",
       "       'Bidirectional RNN', 'Big Transfer (BiT-L)',\n",
       "       'Big Transformer for Back-Translation', 'Big-Little Net',\n",
       "       'Big-Little Net (speech)', 'BigBiGAN', 'BigChaos 2008',\n",
       "       'BigChaos OptiBlend', 'BigGAN-deep 512x512', 'BigSSL',\n",
       "       'Binarized Neural Network (MNIST)', 'BlenderBot 3', 'BloombergGPT',\n",
       "       'Boosting', 'Boss (DARPA Urban Challenge)', 'ByT5-XXL', 'CHAI-1',\n",
       "       'CICERO', 'CLIP (ResNet-50)', 'CLIP (ViT L/14@336px)',\n",
       "       'CNN Best Practices', 'CODEFUSION (Python)', 'CPC v2', 'CPM-Large',\n",
       "       'CRF-RNN', 'CT-MoS (WT2)', 'CTC-Trained LSTM', 'CTM (CIFAR-10)',\n",
       "       'CURL', 'CaLM', 'CamemBERT', 'Cancer drug mechanism prediction',\n",
       "       'CapsNet (MNIST)', 'CapsNet (MultiMNIST)', 'Cascaded LNet-ANet',\n",
       "       'Ceramic-MLP', 'Char-CNN-BiLSTM', 'Character-enriched word2vec',\n",
       "       'ChatGLM3-6B', 'Chinchilla', 'Chinese - English translation',\n",
       "       'Claude', 'Claude 2', 'Claude 2.1', 'Claude 3 Opus',\n",
       "       'Claude 3 Sonnet', 'Claude 3.5 Sonnet', 'CoAtNet', 'CoCa',\n",
       "       'CoEdiT-xxl', 'CoRe', 'CodeT5+', 'CodeT5-base', 'CodeT5-large',\n",
       "       'Codex', 'CogAgent', 'CogVLM-17B', 'CogVideo', 'CogView',\n",
       "       'Cognitron', 'Cohere Embed', 'Conformer',\n",
       "       'Conformer + Wav2vec 2.0 + Noisy Student',\n",
       "       'Constituency-Tree LSTM', 'Context-dependent RNN', 'ContextNet',\n",
       "       'ContextNet + Noisy Student', 'Contriever', 'Conv-DBN',\n",
       "       'ConvNet similarity metric', 'ConvS2S (ensemble of 8 models)',\n",
       "       'Convolutional Pose Machines', 'Cross-Lingual POS Tagger',\n",
       "       'Cross-lingual alignment', 'Cutout-regularized net', 'DALL-E',\n",
       "       'DALL·E 2', 'DALL·E 3', 'DANet', 'DARTS', 'DBLSTM', 'DBRX', 'DCN+',\n",
       "       'DD-PPO', 'DDPM-IP (CelebA)', 'DETR', 'DINOv2', 'DITTO',\n",
       "       'DLRM-2020', 'DMN', 'DNABERT', 'DOT(S)-RNN', 'DQN', 'DQN-2015',\n",
       "       'DeBERTa', 'DeBERTaV3large + KEAR', 'DeLighT', 'DeViSE',\n",
       "       'Decision tree (classification)', 'Decision tree adaline',\n",
       "       'Deconvolutional Network', 'Decoupled weight decay regularization',\n",
       "       'Deep Autoencoders', 'Deep Belief Nets', 'Deep Blue',\n",
       "       'Deep Boltzmann Machines', 'Deep Deterministic Policy Gradients',\n",
       "       'Deep LSTM video classifier', 'Deep Multitask NLP Network',\n",
       "       'Deep rectifier networks', 'DeepFace', 'DeepLab', 'DeepLab (2017)',\n",
       "       'DeepLabV3', 'DeepLabV3+', 'DeepNash', 'DeepNet',\n",
       "       'DeepSeek-Coder-V2 236B', 'DeepSeek-V3', 'DeepSpeech2 (English)',\n",
       "       'DeepStack', 'Deeply-recursive ConvNet', 'Deeply-supervised nets',\n",
       "       'DeiT-B', 'Denoising Autoencoders',\n",
       "       'Denoising Diffusion Probabilistic Models (LSUN Bedroom)',\n",
       "       'DenseNet-264', 'DensePhrases', 'Detic', 'DiT-XL/2',\n",
       "       'DiT-XL/2 + CADS', 'DiT-XL/2 + Discriminator Guidance',\n",
       "       'Diabetic Retinopathy Detection Net', 'DiffDock',\n",
       "       'Differentiable neural computer',\n",
       "       'Diffractive Deep Neural Network', 'Diffusion-GAN',\n",
       "       'Dimensionality Reduction', 'Diplodocus', 'Discriminator Guidance',\n",
       "       'DistBelief NNLM', 'DistBelief Speech', 'DistBelief Vision',\n",
       "       'DistilBERT', 'Distributed representation NN', 'DnCNN',\n",
       "       'Domain Adaptation', 'Doubao-1.5-pro', 'Doubao-pro', 'DrLIM',\n",
       "       'Dropout (CIFAR)', 'Dropout (ImageNet)', 'Dropout (MNIST)',\n",
       "       'Dropout (TIMIT)', 'Dropout-LSTM+Noise(Bernoulli) (WT2)', 'EDSR',\n",
       "       'EI-REHN-1000D', 'ELECTRA', 'ELMo', 'EMDR', 'ENAS',\n",
       "       'EN^2AS with performance reward', 'ERNIE 3.0', 'ERNIE 3.0 Titan',\n",
       "       'ERNIE 3.5', 'ERNIE 4.0', 'ERNIE-Doc (247M)', 'ERNIE-GEN (large)',\n",
       "       'ERNIE-ViLG', 'ESM1b', 'ESM2-15B', 'ESM3 (98B)', 'ESRGAN',\n",
       "       'EVA-01', 'EfficientDet', 'EfficientNet-L2', 'EfficientNetV2-XL',\n",
       "       'EfficientZero', 'Elastic weight consolidation',\n",
       "       'Empirical evaluation of deep architectures', 'EnCodec',\n",
       "       'Enhanced Neighborhood-Based Filtering', 'Error Propagation',\n",
       "       'Eve', 'FAIRSEQ Adaptive Inputs', 'FAST', 'FLAN 137B',\n",
       "       'Falcon-180B', 'Falcon-40B', 'Fast R-CNN', 'Faster R-CNN',\n",
       "       'Feedback Transformer', 'Feedforward NN', 'Ferret (13B)',\n",
       "       'FinGPT-13B', 'Fine-tuned-AWD-LSTM-DOC (fin)', 'Firefly',\n",
       "       'Fisher Kernel GMM', 'Fisher Vector image classifier',\n",
       "       'Fisher-Boost', 'FixRes ResNeXt-101 WSL', 'Flamingo',\n",
       "       'Flan T5-XXL + BLIP-2', 'Flan-PaLM 540B', 'Flan-T5 11B',\n",
       "       'Florence', 'Fractional Max-Pooling', 'Fragment embedding',\n",
       "       'FrameNet role labeling',\n",
       "       'Fraternal dropout + AWD-LSTM 3-layer (WT2)',\n",
       "       'Fully Convolutional Networks', 'FunSearch', 'Fusion in Encoder',\n",
       "       'Fuzzy NN', 'GAN-Advancer', 'GANs', 'GBERT-Large', 'GCNN-14',\n",
       "       'GGNN', 'GL-LWGC-AWD-MoS-LSTM + dynamic evaluation (WT2)', 'GLEE',\n",
       "       'GLIDE', 'GLM-130B', 'GLM-4 (0520)', 'GLaM', 'GNMT',\n",
       "       'GNoME for crystal discovery', 'GOAT', 'GPT-1', 'GPT-2 (1.5B)',\n",
       "       'GPT-3 175B (davinci)', 'GPT-3.5', 'GPT-3.5 Turbo', 'GPT-4',\n",
       "       'GPT-4 Turbo', 'GPT-4V', 'GPT-4o', 'GPT-4o mini', 'GPT-NeoX-20B',\n",
       "       'GPU DBNs', 'GPipe (Amoeba)', 'GPipe (Transformer)', 'GRUs', 'GSM',\n",
       "       'GShard (dense)', 'Galactica', 'Gated HORNN (3rd order)', 'Gato',\n",
       "       'Gemini 1.0 Pro', 'Gemini 1.0 Ultra', 'Gemini 1.5 Pro',\n",
       "       'Gemini Nano-1', 'Gemini Nano-2', 'Gen-1', 'Gen-2', 'GenSLM',\n",
       "       'Generative BST', 'Genetic algorithm', 'German ELECTRA Large',\n",
       "       'GloVe (32B)', 'GloVe (6B)', 'Go-explore', 'Goat-7B', 'Golem',\n",
       "       'GoogLeNet / InceptionV1', 'Gopher (280B)',\n",
       "       'Gradient Boosting Machine', 'Graph-based structural reasoning',\n",
       "       'GraphCast', 'Greedy layer-wise DNN training', 'Grok-1', 'Grok-2',\n",
       "       'GroupLens', 'HLBL', 'HMM Word Alignment', 'HOGWILD!', 'HRA',\n",
       "       'Hanabi 4 player', 'Handwritten Digit Recognition System',\n",
       "       'Heuristic Reinforcement Learning', 'Hierarchical Cognitron',\n",
       "       'Hierarchical LM', 'Hiero', 'Histograms of Oriented Gradients',\n",
       "       'Hopfield Networks (2020)', 'Hopfield network', 'HuBERT',\n",
       "       'Hunyuan-Large', 'Hybrid H3-2.7B', 'HyenaDNA', 'HyperCLOVA 204B',\n",
       "       'HyperNEAT', 'IBM Model 4', 'IBM-5', 'IMPALA', 'ISR network',\n",
       "       'ISS', 'Image generation', 'Image-to-image cGAN', 'ImageBind',\n",
       "       'Imagen', 'Immediate trihead', 'Inception v3',\n",
       "       'Inception-ResNet-V2', 'Inceptionv4', 'Incoder-6.7B',\n",
       "       'Inflated 3D ConvNet', 'Inflection-2', 'Inflection-2.5',\n",
       "       'Innervator', 'InstructBLIP', 'InstructGPT 1.3B',\n",
       "       'InstructGPT 175B', 'InstructGPT 6B', 'InternImage', 'InternLM',\n",
       "       'Internal functionality of visual invariants', 'Invariant CNN',\n",
       "       'Invariant image recognition', 'Iterative Bootstrapping WSD',\n",
       "       'JFT', 'JPMAX', 'Jais', 'Jamba 1.5-Large', 'Jurassic-1-Jumbo',\n",
       "       'KEPLER', 'KN-LM', 'KataGo', 'Kohonen network', 'LDA', 'LDM-1.45B',\n",
       "       'LEP-AD', 'LISSOM', 'LLaMA-65B', 'LLaVA', 'LLaVA 1.5', 'LMICA',\n",
       "       'LMS', 'LMSI-Palm', 'LRCN', 'LRSO-GAN', 'LSTM', 'LSTM (2018)',\n",
       "       'LSTM (Hebbian, Cache, MbPA)', 'LSTM + dynamic eval', 'LSTM LM',\n",
       "       'LSTM with forget gates', 'LSTM+NeuralCache', 'LSTM-300units',\n",
       "       'LSTM-Char-Large', 'LTE speaker verification system', 'LTM-1',\n",
       "       'LUKE', 'LaMDA', 'LaNet-L (CIFAR-10)', 'Large regularized LSTM',\n",
       "       'LeNet-5', 'Learnability theory of language development',\n",
       "       'Libratus', 'Linear Decision Functions',\n",
       "       'Listen, Attend and Spell', 'Llama 2-70B', 'Llama 2-7B',\n",
       "       'Llama 3-70B', 'Llama 3.1-405B', 'Llama 3.3', 'Llama Guard',\n",
       "       'Local Binary Patterns for facial recognition', 'LongT5', 'M4-50B',\n",
       "       'M6-T', 'MADALINE I', 'MCDNN (MNIST)', 'MEB', 'MLN-ASR',\n",
       "       'MLP baggage detector', 'MM1-30B', 'MMLSTM', 'MS-CNN',\n",
       "       'MSA Transformer', 'MSRA (C, PReLU)', 'MT-DNN', 'MUSIC perceptron',\n",
       "       'MV-RNN', 'Make-A-Video', 'Mamba-24M (SC09)', 'Mask R-CNN',\n",
       "       'Masked Autoencoders ViT-H', 'MatrixFac for Recommenders',\n",
       "       'Max-Margin Markov Networks',\n",
       "       'Maximum Entropy Models for machine translation',\n",
       "       'Maximum compute', 'Maximum data', 'Maximum parameters',\n",
       "       'Maxout Networks', 'MedBERT', 'Meena', 'MegaScale (Production)',\n",
       "       'MegaSyn', 'Megatron-BERT', 'Megatron-LM (8.3B)',\n",
       "       'Megatron-Turing NLG 530B', 'MemoReader',\n",
       "       'Mesh-TensorFlow Transformer 2.9B (translation)',\n",
       "       'Mesh-TensorFlow Transformer 4.9B (language)', 'MetNet',\n",
       "       'Meta Pseudo Labels', 'MetaLM', 'MetaMimic', 'Mid-level Features',\n",
       "       'Midjourney V1', 'Minerva (540B)', 'Mistral Large',\n",
       "       'Mistral Large 2', 'Mitosis', 'Mixtral 8x7B',\n",
       "       'Mixture of linear models', 'MnasNet-A1 + SSDLite', 'MnasNet-A3',\n",
       "       'Mnemonic Reader', 'MoCo', 'MoE-Multi', 'MobileNet', 'MobileNetV2',\n",
       "       'Mogrifier (d2, MoS2, MC) + dynamic eval', 'Mogrifier RLSTM (WT2)',\n",
       "       'Monocular Depth Prediction', 'Motion-Driven 3D Feature Tracking',\n",
       "       'Movie Gen Video', 'MuZero', 'Multi-cell LSTM',\n",
       "       'Multi-scale Dilated CNN', 'Multi-task Cascaded CNN',\n",
       "       'MultiBand Diffusion', 'Multilingual DNN', 'Multiresolution CNN',\n",
       "       'Multiscale deformable part model', 'MusicGen', 'MusicLM',\n",
       "       'NAS with base 8 and shared embeddings', 'NAS+ESS (156M)',\n",
       "       'NASNet-A', 'NASv3 (CIFAR-10)', 'NEAT', 'NLLB', 'NLP from scratch',\n",
       "       'NMT Transformer 437M', 'NPLM', 'NTM', 'NVLM-D 72B', 'NVLM-H 72B',\n",
       "       'NVLM-X 72B', 'Named Entity Recognition model', 'Nemotron-3-8B',\n",
       "       'Nemotron-4 340B', 'Neocognitron', 'NetTalk (dictionary)',\n",
       "       'NetTalk (transcription)', 'Netflix Recommender System',\n",
       "       'Network in Network', 'NeuMF (Pinterest)', 'Neural LM',\n",
       "       'Neuro-Symbolic Concept Learner', 'NeuroChess',\n",
       "       'Noisy Student (L2)', 'NoisyNet-Dueling', 'Nucleotide Transformer',\n",
       "       'NÜWA', 'ONE-PEACE', 'OPT-175B', 'OR-WideResNet', 'OmegaPLM',\n",
       "       'OmniVec', 'Once for All', 'OntoProtein', 'OpenAI Five',\n",
       "       'OpenAI Five Rerun', 'OpenAI TI7 DOTA 1v1', 'OpenVLA',\n",
       "       'Optimized Multi-Scale Edge Detection',\n",
       "       'Optimized Single-layer Net', 'OverFeat',\n",
       "       'PDP model for serial order', 'PG-SWGAN', 'PLATO-XL', 'PLUG',\n",
       "       'PNAS-net', 'PNASNet-5', 'PPLX-70B-Online', 'PSPNet', 'PaLI',\n",
       "       'PaLI-X', 'PaLM (540B)', 'PaLM 2', 'PaLM-E', 'Palmyra X 003',\n",
       "       'Palmyra X 004', 'PanGu-Σ', 'Pandemonium (morse)', 'Pangu-Weather',\n",
       "       'Paragraph Vector', 'Part-of-sentence tagging model', 'Parti',\n",
       "       'Pattern recognition and reading by machine', 'PeptideBERT',\n",
       "       'Perceiver IO (optical flow)', 'Perceptron (1960)',\n",
       "       'Perceptron Mark I', 'Perceptron for Large Margin Classification',\n",
       "       'PermuteFormer', 'Phenaki', 'Photo-Geometric Autoencoder',\n",
       "       'Phrase-based translation', 'PhraseCond', 'Piecewise linear model',\n",
       "       'Pixtral Large', 'Pluribus', 'PoE MNIST', 'PointNet', 'PointNet++',\n",
       "       'Pointer Sentinel-LSTM (medium)', 'PolyCoder', 'PolyNet',\n",
       "       'Population-based DRL', 'Pragmatic Theory solution (Netflix 2009)',\n",
       "       'PreTrans-3L-250H', 'Predictive Coding NN',\n",
       "       'Print Recognition Logic', 'ProBERTa', 'ProGen2-xlarge',\n",
       "       'ProgressiveGAN', 'Projected GAN', 'ProtBERT-BFD', 'ProtT5-XXL',\n",
       "       'ProtT5-XXL-BFD', 'ProteinBERT', 'ProteinDT',\n",
       "       'Prototypical networks', 'ProxylessNAS', 'PyramidNet',\n",
       "       'Q-learning', 'QRNN', 'QT-Opt', 'Qwen-72B', 'Qwen-Audio-Chat',\n",
       "       'Qwen-VL', 'Qwen-VL-Max', 'Qwen1.5-72B', 'Qwen2-72B',\n",
       "       'Qwen2.5-72B', 'R-CNN (T-net)', 'R-FCN', 'RAAM',\n",
       "       'RBM Image Classifier', 'RCAN', 'RCTM', 'RETRO-7B', 'RNN LM',\n",
       "       'RNN for 1B words', 'RNN+LDA+KN5+cache',\n",
       "       'RNN+weight noise+dynamic eval', 'RNN-SpeedUp', 'RNN-WER',\n",
       "       'RNNsearch-50*', 'RNTN', 'RT-1', 'RT-2', 'RT-2-X', 'RT-Trajectory',\n",
       "       'Random Decision Forests', 'RankNet', 'Rational DQN Average',\n",
       "       'ReALM', 'ReLU (LFW)', 'ReLU (NORB)', 'ReLU-Speech',\n",
       "       'Reading Twice for NLU', 'Recursive Neural Network',\n",
       "       'Recursive sentiment autoencoder', 'RefineNet',\n",
       "       'Refined Part Pooling',\n",
       "       'Regularized SVD for Collaborative Filtering', 'Reka Core',\n",
       "       'Relational Memory Core', 'ResNeXt-101 32x48d',\n",
       "       'ResNeXt-101 Billion-scale', 'ResNeXt-50', 'ResNet-1001',\n",
       "       'ResNet-110 (CIFAR-10)', 'ResNet-152 (ImageNet)',\n",
       "       'ResNet-152 + ObjectNet', 'ResNet-200', 'ResNet-50 Billion-scale',\n",
       "       'Residual Dense Network', 'Restricted Bolzmann machines',\n",
       "       'RetinaNet-R101', 'RetinaNet-R50', 'Retrieval-Augmented Generator',\n",
       "       'RoBERTa Large', 'RoboCat', 'Robot Parkour', 'Rotation',\n",
       "       'Routing Transformer (WT-103)', 'S-Norm', 'S4', 'SACHS', 'SB-LM',\n",
       "       'SC-NLM', 'SEER', 'SENet (ImageNet)', 'SNARC', 'SNM-skip',\n",
       "       'SPHINX (Llama 2 13B)', 'SPIDER2', 'SPN-4+KN5', 'SPPNet', 'SRGAN',\n",
       "       'SRN-Encoded Grammatical Structures', 'SRU++ Large', 'SSD',\n",
       "       'ST-MoE', 'SVD in recommender systems', 'SVM for face detection',\n",
       "       'Samuel Neural Checkers', 'Sandwich Transformer', 'SciBERT',\n",
       "       'SeamlessM4T', 'Search-Proven Best LSTM',\n",
       "       'Segatron-XL large, M=384 + HCP', 'Segment Anything Model',\n",
       "       'Selective Search', 'Self Organizing System', 'SemExp', 'SemVec',\n",
       "       'Semantic Hashing', 'Semi-Supervised Embedding for DL',\n",
       "       'Seq2Seq LSTM', 'Sequence-based pattern recognition',\n",
       "       'SexNet classification', 'SexNet compression', 'Show-1',\n",
       "       'ShuffleNet v1', 'ShuffleNet v2', 'Siamese-TDNN', 'SimCLR',\n",
       "       'SimCLRv2', 'SimCSE', 'SimpleNet', 'Skywork-13B', 'SmooCT',\n",
       "       'Social and content-based classification', 'Sora', 'Sora Turbo',\n",
       "       'Sparse Energy-Based Model', 'Sparse Vision Encoding',\n",
       "       'Sparse all-MLP', 'Sparse coding model for V1 receptive fields',\n",
       "       'Sparse digit recognition SVM', 'Spatial Pyramid Matching',\n",
       "       'Spatially-Sparse CNN', 'Spatiotemporal fusion ConvNet',\n",
       "       'Speaker-independent vowel classification', 'SpecAugment',\n",
       "       'Spectrally Normalized GAN', 'SqueezeNet',\n",
       "       'Stable Diffusion (LDM-KL-8-G)', 'Stable Diffusion XL (SDXL)',\n",
       "       'Stacked Denoising Autoencoders', 'Stacked hourglass network',\n",
       "       'Stanley (DARPA Grand Challenge 2)', 'StarCoder', 'StarGAN v2',\n",
       "       'Statement Curriculum Learning',\n",
       "       'Statistical Shape Constellations',\n",
       "       'Statistical continuous speech recognizer', 'Student of Games',\n",
       "       'Suno v4', 'Super-vector coding', 'Support Vector Machines',\n",
       "       'Swift', 'Swin Transformer V2 (SwinV2-G)', 'Switch',\n",
       "       'Symmetric Residual Encoder-Decoder Net', 'System 11', 'T0-XXL',\n",
       "       'T5-11B', 'T5-3B', 'TCAN (WT2)', 'TCN (P-MNIST)', 'TD(0)',\n",
       "       'TD-Gammon', 'TFE SVM', 'TRPO', 'TSN', 'TaLK Convolution',\n",
       "       'Table Tennis Agent', 'Tacotron 2', 'Tagging via Viterbi Decoding',\n",
       "       'Tensor-Transformer(1core)+PN (WT103)', 'TensorReasoner',\n",
       "       'Tensorized Transformer (257M)', 'Textual Imager', 'Theseus',\n",
       "       'Theseus 6/768', 'Thumbs Up?', 'Time-delay neural networks',\n",
       "       'TrOCR', 'Trajectory-pooled conv nets', 'TranceptEve',\n",
       "       'Tranception', 'TransE', 'Transformer (2017)',\n",
       "       'Transformer (Adaptive Input Embeddings) WT103',\n",
       "       'Transformer + Simple Recurrent Unit',\n",
       "       'Transformer - LibriVox + Decoding/Rescoring', 'Transformer ELMo',\n",
       "       'Transformer local-attention (NesT-B)', 'Transformer-XL (257M)',\n",
       "       'Transformer-XL + RMS dynamic eval',\n",
       "       'Transformer-XL DeFINE (141M)',\n",
       "       'Transformer-XL Large + Phrase Induction',\n",
       "       'TransformerXL + spectrum control', 'TrellisNet', 'TriNet',\n",
       "       'Truck backer-upper', 'True-Regularization+Finetune+Dynamic-Eval',\n",
       "       'Turing-NLG', 'Two-stream ConvNets for action recognition',\n",
       "       'U-PaLM (540B)', 'UDSMProt', 'UL2', 'ULM-FiT', 'UnifiedQA',\n",
       "       'Unsupervised High-level Feature Learner',\n",
       "       'Unsupervised Scale-Invariant Learning', 'VALL-E',\n",
       "       'VD-LSTM+REAL Large', 'VD-RHN', 'VGG16', 'VGG19', 'VQGAN + CLIP',\n",
       "       'Variational (untied weights, MC) LSTM (Large)',\n",
       "       'Vector Space Model', 'Veo 2', 'ViT + DINO', 'ViT-22B',\n",
       "       'ViT-Base/32', 'ViT-G (model soup)', 'ViT-G/14', 'ViT-G/14 (LiT)',\n",
       "       'ViT-Huge/14', 'VideoMAE V2', 'Visualizing CNNs', 'Volcano 13B',\n",
       "       'W2v-BERT', 'WGAN-GP', 'Walking Minotaur robot', 'WaveNet',\n",
       "       'WeNet (Penn Treebank)', 'Weight Decay', 'Whisper', 'Wide & Deep',\n",
       "       'Wide Residual Network', 'Word Representations',\n",
       "       'Word2Vec (large)', 'Word2Vec (small)', 'XGLM-7.5B', 'XLM',\n",
       "       'XLM-RoBERTa', 'XLMR-XXL', 'XLNet', 'Xception', 'YOLO', 'YOLOX-X',\n",
       "       'YOLOv2', 'YOLOv3', 'Yi-34B',\n",
       "       'YouTube Video Recommendation System',\n",
       "       'Youtube recommendation model', 'Yuan 1.0', 'Zidong Taichu',\n",
       "       'Zoneout + Variational LSTM (WT2)',\n",
       "       'aLSTM(depth-2)+RecurrentPolicy (WT2)', 'base LM+GNN+kNN',\n",
       "       'data2vec (language)', 'data2vec (speech)', 'data2vec (vision)',\n",
       "       'eDiff-I', 'fastText', 'genCNN + dyn eval', 'iGPT-L', 'iGPT-XL',\n",
       "       'mPLUG-Owl2', 'mT0-13B', 'mT5-XXL', 'o1', 'o1-preview',\n",
       "       'top-down frozen classifier', 'wave2vec 2.0 LARGE',\n",
       "       'xTrimoPGLM -100B', 'λ-WASP'], dtype=object)"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_training_df['entities'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entities</th>\n",
       "      <th>years</th>\n",
       "      <th>public_health_expenditure_share_gdp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>1880</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>1890</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>1900</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>1910</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>1920</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2249</th>\n",
       "      <td>United States</td>\n",
       "      <td>2019</td>\n",
       "      <td>13.694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2250</th>\n",
       "      <td>United States</td>\n",
       "      <td>2020</td>\n",
       "      <td>15.694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2251</th>\n",
       "      <td>United States</td>\n",
       "      <td>2021</td>\n",
       "      <td>14.431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2252</th>\n",
       "      <td>United States</td>\n",
       "      <td>2022</td>\n",
       "      <td>13.786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2253</th>\n",
       "      <td>United States</td>\n",
       "      <td>2023</td>\n",
       "      <td>13.898</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2254 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           entities  years  public_health_expenditure_share_gdp\n",
       "0         Argentina   1880                                0.000\n",
       "1         Argentina   1890                                0.000\n",
       "2         Argentina   1900                                0.000\n",
       "3         Argentina   1910                                0.000\n",
       "4         Argentina   1920                                0.000\n",
       "...             ...    ...                                  ...\n",
       "2249  United States   2019                               13.694\n",
       "2250  United States   2020                               15.694\n",
       "2251  United States   2021                               14.431\n",
       "2252  United States   2022                               13.786\n",
       "2253  United States   2023                               13.898\n",
       "\n",
       "[2254 rows x 3 columns]"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "health_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['Argentina', 'Australia', 'Austria', 'Belgium', 'Brazil',\n",
       "        'Bulgaria', 'Canada', 'Chile', 'China', 'Colombia', 'Costa Rica',\n",
       "        'Croatia', 'Cyprus', 'Czechia', 'Denmark', 'Estonia', 'Finland',\n",
       "        'France', 'Germany', 'Greece', 'Hungary', 'Iceland', 'India',\n",
       "        'Indonesia', 'Ireland', 'Israel', 'Italy', 'Japan', 'Latvia',\n",
       "        'Lithuania', 'Luxembourg', 'Malta', 'Mexico', 'Netherlands',\n",
       "        'New Zealand', 'Norway', 'Peru', 'Poland', 'Portugal', 'Romania',\n",
       "        'Slovakia', 'Slovenia', 'South Africa', 'South Korea', 'Spain',\n",
       "        'Sweden', 'Switzerland', 'Turkey', 'Ukraine', 'United Kingdom',\n",
       "        'United States'], dtype=object),\n",
       " array([1880, 1890, 1900, 1910, 1920, 1930, 2000, 2001, 2002, 2003, 2004,\n",
       "        2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015,\n",
       "        2016, 2017, 2018, 2019, 2020, 2021, 1960, 1961, 1962, 1963, 1964,\n",
       "        1965, 1966, 1967, 1968, 1969, 1970, 1971, 1972, 1973, 1974, 1975,\n",
       "        1976, 1977, 1978, 1979, 1980, 1981, 1982, 1983, 1984, 1985, 1986,\n",
       "        1987, 1988, 1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997,\n",
       "        1998, 1999, 2022, 2023]))"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Auch hier sind die Entities verschieden bezüglich der Anzahl Länder + Jahren (ggf. gemeinsame Entities finden über alle Datensätze)\n",
    "health_df['entities'].unique(), health_df['years'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entities</th>\n",
       "      <th>years</th>\n",
       "      <th>median_age__sex_all__age_all__variant_estimates</th>\n",
       "      <th>median_age__sex_all__age_all__variant_medium</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1950</td>\n",
       "      <td>18.395</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1951</td>\n",
       "      <td>18.370</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1952</td>\n",
       "      <td>18.333</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1953</td>\n",
       "      <td>18.289</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1954</td>\n",
       "      <td>18.239</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38198</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2096</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38199</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2097</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38200</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2098</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38201</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2099</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38202</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38203 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          entities  years  median_age__sex_all__age_all__variant_estimates  \\\n",
       "0      Afghanistan   1950                                           18.395   \n",
       "1      Afghanistan   1951                                           18.370   \n",
       "2      Afghanistan   1952                                           18.333   \n",
       "3      Afghanistan   1953                                           18.289   \n",
       "4      Afghanistan   1954                                           18.239   \n",
       "...            ...    ...                                              ...   \n",
       "38198     Zimbabwe   2096                                              NaN   \n",
       "38199     Zimbabwe   2097                                              NaN   \n",
       "38200     Zimbabwe   2098                                              NaN   \n",
       "38201     Zimbabwe   2099                                              NaN   \n",
       "38202     Zimbabwe   2100                                              NaN   \n",
       "\n",
       "       median_age__sex_all__age_all__variant_medium  \n",
       "0                                               NaN  \n",
       "1                                               NaN  \n",
       "2                                               NaN  \n",
       "3                                               NaN  \n",
       "4                                               NaN  \n",
       "...                                             ...  \n",
       "38198                                        34.802  \n",
       "38199                                        35.022  \n",
       "38200                                        35.241  \n",
       "38201                                        35.463  \n",
       "38202                                        35.684  \n",
       "\n",
       "[38203 rows x 4 columns]"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bis jetzt der grösste Datensatz. WICHTIG: median_age__sex_all__age_all__variant_estimates sind Historische Daten und median_age__sex_all__age_all__variant_medium sind Prognosen\n",
    "median_age_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['Afghanistan', 'Africa (UN)', 'Albania', 'Algeria',\n",
       "        'American Samoa', 'Andorra', 'Angola', 'Anguilla',\n",
       "        'Antigua and Barbuda', 'Argentina', 'Armenia', 'Aruba',\n",
       "        'Asia (UN)', 'Australia', 'Austria', 'Azerbaijan', 'Bahamas',\n",
       "        'Bahrain', 'Bangladesh', 'Barbados', 'Belarus', 'Belgium',\n",
       "        'Belize', 'Benin', 'Bermuda', 'Bhutan', 'Bolivia',\n",
       "        'Bonaire Sint Eustatius and Saba', 'Bosnia and Herzegovina',\n",
       "        'Botswana', 'Brazil', 'British Virgin Islands', 'Brunei',\n",
       "        'Bulgaria', 'Burkina Faso', 'Burundi', 'Cambodia', 'Cameroon',\n",
       "        'Canada', 'Cape Verde', 'Cayman Islands',\n",
       "        'Central African Republic', 'Chad', 'Chile', 'China', 'Colombia',\n",
       "        'Comoros', 'Congo', 'Cook Islands', 'Costa Rica', \"Cote d'Ivoire\",\n",
       "        'Croatia', 'Cuba', 'Curacao', 'Cyprus', 'Czechia',\n",
       "        'Democratic Republic of Congo', 'Denmark', 'Djibouti', 'Dominica',\n",
       "        'Dominican Republic', 'East Timor', 'Ecuador', 'Egypt',\n",
       "        'El Salvador', 'Equatorial Guinea', 'Eritrea', 'Estonia',\n",
       "        'Eswatini', 'Ethiopia', 'Europe (UN)', 'Falkland Islands',\n",
       "        'Faroe Islands', 'Fiji', 'Finland', 'France', 'French Guiana',\n",
       "        'French Polynesia', 'Gabon', 'Gambia', 'Georgia', 'Germany',\n",
       "        'Ghana', 'Gibraltar', 'Greece', 'Greenland', 'Grenada',\n",
       "        'Guadeloupe', 'Guam', 'Guatemala', 'Guernsey', 'Guinea',\n",
       "        'Guinea-Bissau', 'Guyana', 'Haiti', 'High-income countries',\n",
       "        'Honduras', 'Hong Kong', 'Hungary', 'Iceland', 'India',\n",
       "        'Indonesia', 'Iran', 'Iraq', 'Ireland', 'Isle of Man', 'Israel',\n",
       "        'Italy', 'Jamaica', 'Japan', 'Jersey', 'Jordan', 'Kazakhstan',\n",
       "        'Kenya', 'Kiribati', 'Kosovo', 'Kuwait', 'Kyrgyzstan', 'Laos',\n",
       "        'Latin America and the Caribbean (UN)', 'Latvia',\n",
       "        'Least developed countries', 'Lebanon', 'Lesotho',\n",
       "        'Less developed regions',\n",
       "        'Less developed regions, excluding China',\n",
       "        'Less developed regions, excluding least developed countries',\n",
       "        'Liberia', 'Libya', 'Liechtenstein', 'Lithuania',\n",
       "        'Low-income countries', 'Lower-middle-income countries',\n",
       "        'Luxembourg', 'Macao', 'Madagascar', 'Malawi', 'Malaysia',\n",
       "        'Maldives', 'Mali', 'Malta', 'Marshall Islands', 'Martinique',\n",
       "        'Mauritania', 'Mauritius', 'Mayotte', 'Mexico',\n",
       "        'Micronesia (country)', 'Moldova', 'Monaco', 'Mongolia',\n",
       "        'Montenegro', 'Montserrat', 'More developed regions', 'Morocco',\n",
       "        'Mozambique', 'Myanmar', 'Namibia', 'Nauru', 'Nepal',\n",
       "        'Netherlands', 'New Caledonia', 'New Zealand', 'Nicaragua',\n",
       "        'Niger', 'Nigeria', 'Niue', 'North Korea', 'North Macedonia',\n",
       "        'Northern America (UN)', 'Northern Mariana Islands', 'Norway',\n",
       "        'Oceania (UN)', 'Oman', 'Pakistan', 'Palau', 'Palestine', 'Panama',\n",
       "        'Papua New Guinea', 'Paraguay', 'Peru', 'Philippines', 'Poland',\n",
       "        'Portugal', 'Puerto Rico', 'Qatar', 'Reunion', 'Romania', 'Russia',\n",
       "        'Rwanda', 'Saint Barthelemy', 'Saint Helena',\n",
       "        'Saint Kitts and Nevis', 'Saint Lucia',\n",
       "        'Saint Martin (French part)', 'Saint Pierre and Miquelon',\n",
       "        'Saint Vincent and the Grenadines', 'Samoa', 'San Marino',\n",
       "        'Sao Tome and Principe', 'Saudi Arabia', 'Senegal', 'Serbia',\n",
       "        'Seychelles', 'Sierra Leone', 'Singapore',\n",
       "        'Sint Maarten (Dutch part)', 'Slovakia', 'Slovenia',\n",
       "        'Solomon Islands', 'Somalia', 'South Africa', 'South Korea',\n",
       "        'South Sudan', 'Spain', 'Sri Lanka', 'Sudan', 'Suriname', 'Sweden',\n",
       "        'Switzerland', 'Syria', 'Taiwan', 'Tajikistan', 'Tanzania',\n",
       "        'Thailand', 'Togo', 'Tokelau', 'Tonga', 'Trinidad and Tobago',\n",
       "        'Tunisia', 'Turkey', 'Turkmenistan', 'Turks and Caicos Islands',\n",
       "        'Tuvalu', 'Uganda', 'Ukraine', 'United Arab Emirates',\n",
       "        'United Kingdom', 'United States', 'United States Virgin Islands',\n",
       "        'Upper-middle-income countries', 'Uruguay', 'Uzbekistan',\n",
       "        'Vanuatu', 'Vatican', 'Venezuela', 'Vietnam', 'Wallis and Futuna',\n",
       "        'Western Sahara', 'World', 'Yemen', 'Zambia', 'Zimbabwe'],\n",
       "       dtype=object),\n",
       " array([1950, 1951, 1952, 1953, 1954, 1955, 1956, 1957, 1958, 1959, 1960,\n",
       "        1961, 1962, 1963, 1964, 1965, 1966, 1967, 1968, 1969, 1970, 1971,\n",
       "        1972, 1973, 1974, 1975, 1976, 1977, 1978, 1979, 1980, 1981, 1982,\n",
       "        1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993,\n",
       "        1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004,\n",
       "        2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015,\n",
       "        2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2024, 2025, 2026,\n",
       "        2027, 2028, 2029, 2030, 2031, 2032, 2033, 2034, 2035, 2036, 2037,\n",
       "        2038, 2039, 2040, 2041, 2042, 2043, 2044, 2045, 2046, 2047, 2048,\n",
       "        2049, 2050, 2051, 2052, 2053, 2054, 2055, 2056, 2057, 2058, 2059,\n",
       "        2060, 2061, 2062, 2063, 2064, 2065, 2066, 2067, 2068, 2069, 2070,\n",
       "        2071, 2072, 2073, 2074, 2075, 2076, 2077, 2078, 2079, 2080, 2081,\n",
       "        2082, 2083, 2084, 2085, 2086, 2087, 2088, 2089, 2090, 2091, 2092,\n",
       "        2093, 2094, 2095, 2096, 2097, 2098, 2099, 2100]))"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wieder massiv mehr Entities\n",
    "median_age_df['entities'].unique(), median_age_df['years'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entities</th>\n",
       "      <th>years</th>\n",
       "      <th>dependency_ratio__sex_all__age_old__variant_estimates</th>\n",
       "      <th>dependency_ratio__sex_all__age_youth__variant_estimates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1950</td>\n",
       "      <td>5.078875</td>\n",
       "      <td>73.154760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1951</td>\n",
       "      <td>5.100585</td>\n",
       "      <td>73.256740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1952</td>\n",
       "      <td>5.114400</td>\n",
       "      <td>73.390884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1953</td>\n",
       "      <td>5.122446</td>\n",
       "      <td>73.564835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1954</td>\n",
       "      <td>5.126268</td>\n",
       "      <td>73.813896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18939</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2019</td>\n",
       "      <td>6.552438</td>\n",
       "      <td>78.893740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18940</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2020</td>\n",
       "      <td>6.602380</td>\n",
       "      <td>77.780350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18941</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2021</td>\n",
       "      <td>6.596693</td>\n",
       "      <td>76.786766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18942</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2022</td>\n",
       "      <td>6.585346</td>\n",
       "      <td>75.960910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18943</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2023</td>\n",
       "      <td>6.570403</td>\n",
       "      <td>75.053520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18944 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          entities  years  \\\n",
       "0      Afghanistan   1950   \n",
       "1      Afghanistan   1951   \n",
       "2      Afghanistan   1952   \n",
       "3      Afghanistan   1953   \n",
       "4      Afghanistan   1954   \n",
       "...            ...    ...   \n",
       "18939     Zimbabwe   2019   \n",
       "18940     Zimbabwe   2020   \n",
       "18941     Zimbabwe   2021   \n",
       "18942     Zimbabwe   2022   \n",
       "18943     Zimbabwe   2023   \n",
       "\n",
       "       dependency_ratio__sex_all__age_old__variant_estimates  \\\n",
       "0                                               5.078875       \n",
       "1                                               5.100585       \n",
       "2                                               5.114400       \n",
       "3                                               5.122446       \n",
       "4                                               5.126268       \n",
       "...                                                  ...       \n",
       "18939                                           6.552438       \n",
       "18940                                           6.602380       \n",
       "18941                                           6.596693       \n",
       "18942                                           6.585346       \n",
       "18943                                           6.570403       \n",
       "\n",
       "       dependency_ratio__sex_all__age_youth__variant_estimates  \n",
       "0                                              73.154760        \n",
       "1                                              73.256740        \n",
       "2                                              73.390884        \n",
       "3                                              73.564835        \n",
       "4                                              73.813896        \n",
       "...                                                  ...        \n",
       "18939                                          78.893740        \n",
       "18940                                          77.780350        \n",
       "18941                                          76.786766        \n",
       "18942                                          75.960910        \n",
       "18943                                          75.053520        \n",
       "\n",
       "[18944 rows x 4 columns]"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dependency_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['Afghanistan', 'Africa (UN)', 'Albania', 'Algeria',\n",
       "        'American Samoa', 'Americas (UN)', 'Andorra', 'Angola', 'Anguilla',\n",
       "        'Antigua and Barbuda', 'Argentina', 'Armenia', 'Aruba',\n",
       "        'Asia (UN)', 'Australia', 'Austria', 'Azerbaijan', 'Bahamas',\n",
       "        'Bahrain', 'Bangladesh', 'Barbados', 'Belarus', 'Belgium',\n",
       "        'Belize', 'Benin', 'Bermuda', 'Bhutan', 'Bolivia',\n",
       "        'Bonaire Sint Eustatius and Saba', 'Bosnia and Herzegovina',\n",
       "        'Botswana', 'Brazil', 'British Virgin Islands', 'Brunei',\n",
       "        'Bulgaria', 'Burkina Faso', 'Burundi', 'Cambodia', 'Cameroon',\n",
       "        'Canada', 'Cape Verde', 'Cayman Islands',\n",
       "        'Central African Republic', 'Chad', 'Chile', 'China', 'Colombia',\n",
       "        'Comoros', 'Congo', 'Cook Islands', 'Costa Rica', \"Cote d'Ivoire\",\n",
       "        'Croatia', 'Cuba', 'Curacao', 'Cyprus', 'Czechia',\n",
       "        'Democratic Republic of Congo', 'Denmark', 'Djibouti', 'Dominica',\n",
       "        'Dominican Republic', 'East Timor', 'Ecuador', 'Egypt',\n",
       "        'El Salvador', 'Equatorial Guinea', 'Eritrea', 'Estonia',\n",
       "        'Eswatini', 'Ethiopia', 'Europe (UN)', 'Falkland Islands',\n",
       "        'Faroe Islands', 'Fiji', 'Finland', 'France', 'French Guiana',\n",
       "        'French Polynesia', 'Gabon', 'Gambia', 'Georgia', 'Germany',\n",
       "        'Ghana', 'Gibraltar', 'Greece', 'Greenland', 'Grenada',\n",
       "        'Guadeloupe', 'Guam', 'Guatemala', 'Guernsey', 'Guinea',\n",
       "        'Guinea-Bissau', 'Guyana', 'Haiti', 'High-income countries',\n",
       "        'Honduras', 'Hong Kong', 'Hungary', 'Iceland', 'India',\n",
       "        'Indonesia', 'Iran', 'Iraq', 'Ireland', 'Isle of Man', 'Israel',\n",
       "        'Italy', 'Jamaica', 'Japan', 'Jersey', 'Jordan', 'Kazakhstan',\n",
       "        'Kenya', 'Kiribati', 'Kosovo', 'Kuwait', 'Kyrgyzstan',\n",
       "        'Land-locked developing countries (LLDC)', 'Laos',\n",
       "        'Latin America and the Caribbean (UN)', 'Latvia',\n",
       "        'Least developed countries', 'Lebanon', 'Lesotho',\n",
       "        'Less developed regions',\n",
       "        'Less developed regions, excluding China',\n",
       "        'Less developed regions, excluding least developed countries',\n",
       "        'Liberia', 'Libya', 'Liechtenstein', 'Lithuania',\n",
       "        'Low-income countries', 'Lower-middle-income countries',\n",
       "        'Luxembourg', 'Macao', 'Madagascar', 'Malawi', 'Malaysia',\n",
       "        'Maldives', 'Mali', 'Malta', 'Marshall Islands', 'Martinique',\n",
       "        'Mauritania', 'Mauritius', 'Mayotte', 'Mexico',\n",
       "        'Micronesia (country)', 'Moldova', 'Monaco', 'Mongolia',\n",
       "        'Montenegro', 'Montserrat', 'More developed regions', 'Morocco',\n",
       "        'Mozambique', 'Myanmar', 'Namibia', 'Nauru', 'Nepal',\n",
       "        'Netherlands', 'New Caledonia', 'New Zealand', 'Nicaragua',\n",
       "        'Niger', 'Nigeria', 'Niue', 'North Korea', 'North Macedonia',\n",
       "        'Northern America (UN)', 'Northern Mariana Islands', 'Norway',\n",
       "        'Oceania (UN)', 'Oman', 'Pakistan', 'Palau', 'Palestine', 'Panama',\n",
       "        'Papua New Guinea', 'Paraguay', 'Peru', 'Philippines', 'Poland',\n",
       "        'Portugal', 'Puerto Rico', 'Qatar', 'Reunion', 'Romania', 'Russia',\n",
       "        'Rwanda', 'Saint Barthelemy', 'Saint Helena',\n",
       "        'Saint Kitts and Nevis', 'Saint Lucia',\n",
       "        'Saint Martin (French part)', 'Saint Pierre and Miquelon',\n",
       "        'Saint Vincent and the Grenadines', 'Samoa', 'San Marino',\n",
       "        'Sao Tome and Principe', 'Saudi Arabia', 'Senegal', 'Serbia',\n",
       "        'Seychelles', 'Sierra Leone', 'Singapore',\n",
       "        'Sint Maarten (Dutch part)', 'Slovakia', 'Slovenia',\n",
       "        'Small island developing states (SIDS)', 'Solomon Islands',\n",
       "        'Somalia', 'South Africa', 'South Korea', 'South Sudan', 'Spain',\n",
       "        'Sri Lanka', 'Sudan', 'Suriname', 'Sweden', 'Switzerland', 'Syria',\n",
       "        'Taiwan', 'Tajikistan', 'Tanzania', 'Thailand', 'Togo', 'Tokelau',\n",
       "        'Tonga', 'Trinidad and Tobago', 'Tunisia', 'Turkey',\n",
       "        'Turkmenistan', 'Turks and Caicos Islands', 'Tuvalu', 'Uganda',\n",
       "        'Ukraine', 'United Arab Emirates', 'United Kingdom',\n",
       "        'United States', 'United States Virgin Islands',\n",
       "        'Upper-middle-income countries', 'Uruguay', 'Uzbekistan',\n",
       "        'Vanuatu', 'Vatican', 'Venezuela', 'Vietnam', 'Wallis and Futuna',\n",
       "        'Western Sahara', 'World', 'Yemen', 'Zambia', 'Zimbabwe'],\n",
       "       dtype=object),\n",
       " array([1950, 1951, 1952, 1953, 1954, 1955, 1956, 1957, 1958, 1959, 1960,\n",
       "        1961, 1962, 1963, 1964, 1965, 1966, 1967, 1968, 1969, 1970, 1971,\n",
       "        1972, 1973, 1974, 1975, 1976, 1977, 1978, 1979, 1980, 1981, 1982,\n",
       "        1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993,\n",
       "        1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004,\n",
       "        2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015,\n",
       "        2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023]))"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wieder massiv mehr Entities\n",
    "dependency_df['entities'].unique(), dependency_df['years'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Konstante Schnittmenge eruiren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl konstanter Entities über den Zeitraum 2013-2020: 20\n",
      "\n",
      "Konstante Entities:\n",
      "['Austria', 'Canada', 'China', 'Denmark', 'Finland', 'France', 'Germany', 'Hungary', 'India', 'Israel', 'Italy', 'Japan', 'Mexico', 'Netherlands', 'Poland', 'South Korea', 'Spain', 'Sweden', 'United Kingdom', 'United States']\n",
      "\n",
      "Überblick pro Jahr:\n",
      "2013: 29 Entities (AI:36, RD:106, Health:50, Age:253, Dep:256)\n",
      "2014: 27 Entities (AI:38, RD:101, Health:50, Age:253, Dep:256)\n",
      "2015: 36 Entities (AI:44, RD:113, Health:50, Age:253, Dep:256)\n",
      "2016: 35 Entities (AI:48, RD:101, Health:51, Age:253, Dep:256)\n",
      "2017: 36 Entities (AI:46, RD:105, Health:51, Age:253, Dep:256)\n",
      "2018: 39 Entities (AI:52, RD:102, Health:51, Age:253, Dep:256)\n",
      "2019: 39 Entities (AI:45, RD:104, Health:51, Age:253, Dep:256)\n",
      "2020: 32 Entities (AI:43, RD:96, Health:50, Age:253, Dep:256)\n"
     ]
    }
   ],
   "source": [
    "def find_constant_entities(start_year=2013, end_year=2020):\n",
    "    # Sammle für jedes Jahr die Entities, die in allen DataFrames vorhanden sind\n",
    "    entities_by_year = {}\n",
    "    \n",
    "    for year in range(start_year, end_year + 1):\n",
    "        # Hole Entities für jedes DataFrame im aktuellen Jahr\n",
    "        year_entities = {\n",
    "            'ai_patents': set(ai_patents_df[ai_patents_df['years'] == year]['entities']),\n",
    "            'rd_gdp': set(rd_gdp_df[rd_gdp_df['years'] == year]['entities']),\n",
    "            'health': set(health_df[health_df['years'] == year]['entities']),\n",
    "            'median_age': set(median_age_df[median_age_df['years'] == year]['entities']),\n",
    "            'dependency': set(dependency_df[dependency_df['years'] == year]['entities'])\n",
    "        }\n",
    "        \n",
    "        # Finde die Schnittmenge für dieses Jahr (nur wenn alle DataFrames Daten haben)\n",
    "        if all(len(entities) > 0 for entities in year_entities.values()):\n",
    "            entities_by_year[year] = set.intersection(*year_entities.values())\n",
    "    \n",
    "    # Finde die Entities, die in ALLEN Jahren vorhanden sind\n",
    "    if not entities_by_year:\n",
    "        return set()\n",
    "    \n",
    "    constant_entities = set.intersection(*entities_by_year.values())\n",
    "    \n",
    "    return constant_entities\n",
    "\n",
    "# Finde die konstanten Entities\n",
    "constant_entities = find_constant_entities()\n",
    "\n",
    "print(f\"Anzahl konstanter Entities über den Zeitraum 2013-2020: {len(constant_entities)}\")\n",
    "print(\"\\nKonstante Entities:\")\n",
    "print(sorted(constant_entities))\n",
    "\n",
    "# Optional: Zeige für jedes Jahr die Anzahl der Entities in jedem DataFrame\n",
    "print(\"\\nÜberblick pro Jahr:\")\n",
    "for year in range(2013, 2021):\n",
    "    year_entities = {\n",
    "        'ai_patents': set(ai_patents_df[ai_patents_df['years'] == year]['entities']),\n",
    "        'rd_gdp': set(rd_gdp_df[rd_gdp_df['years'] == year]['entities']),\n",
    "        'health': set(health_df[health_df['years'] == year]['entities']),\n",
    "        'median_age': set(median_age_df[median_age_df['years'] == year]['entities']),\n",
    "        'dependency': set(dependency_df[dependency_df['years'] == year]['entities'])\n",
    "    }\n",
    "    \n",
    "    # Finde die Schnittmenge für dieses Jahr\n",
    "    if all(len(entities) > 0 for entities in year_entities.values()):\n",
    "        year_intersection = set.intersection(*year_entities.values())\n",
    "        print(f\"{year}: {len(year_intersection)} Entities (AI:{len(year_entities['ai_patents'])}, \"\n",
    "              f\"RD:{len(year_entities['rd_gdp'])}, Health:{len(year_entities['health'])}, \"\n",
    "              f\"Age:{len(year_entities['median_age'])}, Dep:{len(year_entities['dependency'])})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jahr mit der größten Schnittmenge: 2018\n",
      "Anzahl Entities in diesem Jahr: 39\n",
      "\n",
      "Diese Entities sind:\n",
      "['Argentina', 'Austria', 'Belgium', 'Brazil', 'Bulgaria', 'Canada', 'Chile', 'China', 'Croatia', 'Czechia', 'Denmark', 'Finland', 'France', 'Germany', 'Greece', 'Hungary', 'India', 'Ireland', 'Israel', 'Italy', 'Japan', 'Lithuania', 'Luxembourg', 'Mexico', 'Netherlands', 'Norway', 'Peru', 'Poland', 'Portugal', 'Romania', 'Slovenia', 'South Africa', 'South Korea', 'Spain', 'Sweden', 'Turkey', 'Ukraine', 'United Kingdom', 'United States']\n",
      "\n",
      "Verfügbarkeit dieser Entities in anderen Jahren:\n",
      "2013: 27 von 39 Entities verfügbar\n",
      "2014: 27 von 39 Entities verfügbar\n",
      "2015: 32 von 39 Entities verfügbar\n",
      "2016: 34 von 39 Entities verfügbar\n",
      "2017: 34 von 39 Entities verfügbar\n",
      "2018: 39 von 39 Entities verfügbar\n",
      "2019: 35 von 39 Entities verfügbar\n",
      "2020: 31 von 39 Entities verfügbar\n"
     ]
    }
   ],
   "source": [
    "def find_best_year_entities(start_year=2013, end_year=2020):\n",
    "    # Dictionary für die Schnittmengen pro Jahr\n",
    "    intersections_by_year = {}\n",
    "    \n",
    "    for year in range(start_year, end_year + 1):\n",
    "        # Hole Entities für jedes DataFrame im aktuellen Jahr\n",
    "        year_entities = {\n",
    "            'ai_patents': set(ai_patents_df[ai_patents_df['years'] == year]['entities']),\n",
    "            'rd_gdp': set(rd_gdp_df[rd_gdp_df['years'] == year]['entities']),\n",
    "            'health': set(health_df[health_df['years'] == year]['entities']),\n",
    "            'median_age': set(median_age_df[median_age_df['years'] == year]['entities']),\n",
    "            'dependency': set(dependency_df[dependency_df['years'] == year]['entities'])\n",
    "        }\n",
    "        \n",
    "        # Finde die Schnittmenge für dieses Jahr\n",
    "        if all(len(entities) > 0 for entities in year_entities.values()):\n",
    "            year_intersection = set.intersection(*year_entities.values())\n",
    "            intersections_by_year[year] = year_intersection\n",
    "\n",
    "    # Finde das Jahr mit der größten Schnittmenge\n",
    "    best_year = max(intersections_by_year.items(), key=lambda x: len(x[1]))\n",
    "    \n",
    "    return best_year[0], best_year[1]\n",
    "\n",
    "# Finde das beste Jahr und dessen Entities\n",
    "best_year, best_entities = find_best_year_entities()\n",
    "\n",
    "print(f\"Jahr mit der größten Schnittmenge: {best_year}\")\n",
    "print(f\"Anzahl Entities in diesem Jahr: {len(best_entities)}\")\n",
    "print(\"\\nDiese Entities sind:\")\n",
    "print(sorted(best_entities))\n",
    "\n",
    "# Überprüfe die Verfügbarkeit dieser Entities in anderen Jahren\n",
    "print(\"\\nVerfügbarkeit dieser Entities in anderen Jahren:\")\n",
    "for year in range(2013, 2021):\n",
    "    year_entities = {\n",
    "        'ai_patents': set(ai_patents_df[ai_patents_df['years'] == year]['entities']),\n",
    "        'rd_gdp': set(rd_gdp_df[rd_gdp_df['years'] == year]['entities']),\n",
    "        'health': set(health_df[health_df['years'] == year]['entities']),\n",
    "        'median_age': set(median_age_df[median_age_df['years'] == year]['entities']),\n",
    "        'dependency': set(dependency_df[dependency_df['years'] == year]['entities'])\n",
    "    }\n",
    "    \n",
    "    # Prüfe, wie viele der best_entities in diesem Jahr verfügbar sind\n",
    "    available_entities = best_entities.intersection(*year_entities.values())\n",
    "    print(f\"{year}: {len(available_entities)} von {len(best_entities)} Entities verfügbar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ai_patents_filtered:\n",
      "Anzahl Zeilen: 260\n",
      "Unique entities: 39\n",
      "Unique years: [np.int64(2013), np.int64(2014), np.int64(2015), np.int64(2016), np.int64(2017), np.int64(2018), np.int64(2019), np.int64(2020)]\n",
      "Warnung: Erwartete 312 Zeilen, aber hat 260 Zeilen\n",
      "\n",
      "rd_gdp_filtered:\n",
      "Anzahl Zeilen: 312\n",
      "Unique entities: 39\n",
      "Unique years: [np.int64(2013), np.int64(2014), np.int64(2015), np.int64(2016), np.int64(2017), np.int64(2018), np.int64(2019), np.int64(2020)]\n",
      "\n",
      "health_filtered:\n",
      "Anzahl Zeilen: 311\n",
      "Unique entities: 39\n",
      "Unique years: [np.int64(2013), np.int64(2014), np.int64(2015), np.int64(2016), np.int64(2017), np.int64(2018), np.int64(2019), np.int64(2020)]\n",
      "Warnung: Erwartete 312 Zeilen, aber hat 311 Zeilen\n",
      "\n",
      "median_age_filtered:\n",
      "Anzahl Zeilen: 312\n",
      "Unique entities: 39\n",
      "Unique years: [np.int64(2013), np.int64(2014), np.int64(2015), np.int64(2016), np.int64(2017), np.int64(2018), np.int64(2019), np.int64(2020)]\n",
      "\n",
      "dependency_filtered:\n",
      "Anzahl Zeilen: 312\n",
      "Unique entities: 39\n",
      "Unique years: [np.int64(2013), np.int64(2014), np.int64(2015), np.int64(2016), np.int64(2017), np.int64(2018), np.int64(2019), np.int64(2020)]\n"
     ]
    }
   ],
   "source": [
    "# Filtere jeden DataFrame für best_entities und Jahre 2013-2020\n",
    "ai_patents_filtered = ai_patents_df[\n",
    "    (ai_patents_df['entities'].isin(best_entities)) & \n",
    "    (ai_patents_df['years'].between(2013, 2020))\n",
    "]\n",
    "\n",
    "rd_gdp_filtered = rd_gdp_df[\n",
    "    (rd_gdp_df['entities'].isin(best_entities)) & \n",
    "    (rd_gdp_df['years'].between(2013, 2020))\n",
    "]\n",
    "\n",
    "health_filtered = health_df[\n",
    "    (health_df['entities'].isin(best_entities)) & \n",
    "    (health_df['years'].between(2013, 2020))\n",
    "]\n",
    "\n",
    "median_age_filtered = median_age_df[\n",
    "    (median_age_df['entities'].isin(best_entities)) & \n",
    "    (median_age_df['years'].between(2013, 2020))\n",
    "]\n",
    "\n",
    "dependency_filtered = dependency_df[\n",
    "    (dependency_df['entities'].isin(best_entities)) & \n",
    "    (dependency_df['years'].between(2013, 2020))\n",
    "]\n",
    "\n",
    "# Überprüfe die Ergebnisse\n",
    "for name, df in [\n",
    "    ('ai_patents', ai_patents_filtered),\n",
    "    ('rd_gdp', rd_gdp_filtered),\n",
    "    ('health', health_filtered),\n",
    "    ('median_age', median_age_filtered),\n",
    "    ('dependency', dependency_filtered)\n",
    "]:\n",
    "    print(f\"\\n{name}_filtered:\")\n",
    "    print(f\"Anzahl Zeilen: {len(df)}\")\n",
    "    print(f\"Unique entities: {df['entities'].nunique()}\")\n",
    "    print(f\"Unique years: {sorted(df['years'].unique())}\")\n",
    "    \n",
    "    # Überprüfe auf fehlende Kombinationen\n",
    "    expected_combinations = len(best_entities) * 8  # 8 Jahre (2013-2020)\n",
    "    if len(df) != expected_combinations:\n",
    "        print(f\"Warnung: Erwartete {expected_combinations} Zeilen, aber hat {len(df)} Zeilen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ai_patents_filtered (Spalte: num_patent_granted__field_life_sciences):\n",
      "Fehlende Kombinationen: 52\n",
      "Füge hinzu: Entity: Ireland, Year: 2014, Spalten: ['num_patent_granted__field_life_sciences']\n",
      "Füge hinzu: Entity: Ireland, Year: 2017, Spalten: ['num_patent_granted__field_life_sciences']\n",
      "Füge hinzu: Entity: Czechia, Year: 2015, Spalten: ['num_patent_granted__field_life_sciences']\n",
      "Füge hinzu: Entity: Argentina, Year: 2015, Spalten: ['num_patent_granted__field_life_sciences']\n",
      "Füge hinzu: Entity: Slovenia, Year: 2019, Spalten: ['num_patent_granted__field_life_sciences']\n",
      "Füge hinzu: Entity: Ireland, Year: 2020, Spalten: ['num_patent_granted__field_life_sciences']\n",
      "Füge hinzu: Entity: Belgium, Year: 2014, Spalten: ['num_patent_granted__field_life_sciences']\n",
      "Füge hinzu: Entity: Luxembourg, Year: 2015, Spalten: ['num_patent_granted__field_life_sciences']\n",
      "Füge hinzu: Entity: Romania, Year: 2013, Spalten: ['num_patent_granted__field_life_sciences']\n",
      "Füge hinzu: Entity: Greece, Year: 2013, Spalten: ['num_patent_granted__field_life_sciences']\n",
      "Füge hinzu: Entity: Norway, Year: 2014, Spalten: ['num_patent_granted__field_life_sciences']\n",
      "Füge hinzu: Entity: Chile, Year: 2017, Spalten: ['num_patent_granted__field_life_sciences']\n",
      "Füge hinzu: Entity: Chile, Year: 2014, Spalten: ['num_patent_granted__field_life_sciences']\n",
      "Füge hinzu: Entity: Chile, Year: 2020, Spalten: ['num_patent_granted__field_life_sciences']\n",
      "Füge hinzu: Entity: Peru, Year: 2014, Spalten: ['num_patent_granted__field_life_sciences']\n",
      "Füge hinzu: Entity: Czechia, Year: 2014, Spalten: ['num_patent_granted__field_life_sciences']\n",
      "Füge hinzu: Entity: Ireland, Year: 2013, Spalten: ['num_patent_granted__field_life_sciences']\n",
      "Füge hinzu: Entity: Ireland, Year: 2019, Spalten: ['num_patent_granted__field_life_sciences']\n",
      "Füge hinzu: Entity: Peru, Year: 2017, Spalten: ['num_patent_granted__field_life_sciences']\n",
      "Füge hinzu: Entity: Croatia, Year: 2020, Spalten: ['num_patent_granted__field_life_sciences']\n",
      "Füge hinzu: Entity: South Africa, Year: 2013, Spalten: ['num_patent_granted__field_life_sciences']\n",
      "Füge hinzu: Entity: Lithuania, Year: 2013, Spalten: ['num_patent_granted__field_life_sciences']\n",
      "Füge hinzu: Entity: Croatia, Year: 2017, Spalten: ['num_patent_granted__field_life_sciences']\n",
      "Füge hinzu: Entity: Argentina, Year: 2014, Spalten: ['num_patent_granted__field_life_sciences']\n",
      "Füge hinzu: Entity: Belgium, Year: 2013, Spalten: ['num_patent_granted__field_life_sciences']\n",
      "Füge hinzu: Entity: Croatia, Year: 2014, Spalten: ['num_patent_granted__field_life_sciences']\n",
      "Füge hinzu: Entity: South Africa, Year: 2019, Spalten: ['num_patent_granted__field_life_sciences']\n",
      "Füge hinzu: Entity: Luxembourg, Year: 2014, Spalten: ['num_patent_granted__field_life_sciences']\n",
      "Füge hinzu: Entity: Portugal, Year: 2013, Spalten: ['num_patent_granted__field_life_sciences']\n",
      "Füge hinzu: Entity: Chile, Year: 2013, Spalten: ['num_patent_granted__field_life_sciences']\n",
      "Füge hinzu: Entity: Chile, Year: 2019, Spalten: ['num_patent_granted__field_life_sciences']\n",
      "Füge hinzu: Entity: Chile, Year: 2016, Spalten: ['num_patent_granted__field_life_sciences']\n",
      "Füge hinzu: Entity: Bulgaria, Year: 2014, Spalten: ['num_patent_granted__field_life_sciences']\n",
      "Füge hinzu: Entity: Peru, Year: 2013, Spalten: ['num_patent_granted__field_life_sciences']\n",
      "Füge hinzu: Entity: Turkey, Year: 2020, Spalten: ['num_patent_granted__field_life_sciences']\n",
      "Füge hinzu: Entity: Czechia, Year: 2016, Spalten: ['num_patent_granted__field_life_sciences']\n",
      "Füge hinzu: Entity: Croatia, Year: 2013, Spalten: ['num_patent_granted__field_life_sciences']\n",
      "Füge hinzu: Entity: Ireland, Year: 2015, Spalten: ['num_patent_granted__field_life_sciences']\n",
      "Füge hinzu: Entity: Slovenia, Year: 2014, Spalten: ['num_patent_granted__field_life_sciences']\n",
      "Füge hinzu: Entity: Croatia, Year: 2016, Spalten: ['num_patent_granted__field_life_sciences']\n",
      "Füge hinzu: Entity: Belgium, Year: 2015, Spalten: ['num_patent_granted__field_life_sciences']\n",
      "Füge hinzu: Entity: Slovenia, Year: 2017, Spalten: ['num_patent_granted__field_life_sciences']\n",
      "Füge hinzu: Entity: South Africa, Year: 2015, Spalten: ['num_patent_granted__field_life_sciences']\n",
      "Füge hinzu: Entity: Argentina, Year: 2016, Spalten: ['num_patent_granted__field_life_sciences']\n",
      "Füge hinzu: Entity: Slovenia, Year: 2020, Spalten: ['num_patent_granted__field_life_sciences']\n",
      "Füge hinzu: Entity: Luxembourg, Year: 2013, Spalten: ['num_patent_granted__field_life_sciences']\n",
      "Füge hinzu: Entity: Ukraine, Year: 2020, Spalten: ['num_patent_granted__field_life_sciences']\n",
      "Füge hinzu: Entity: Romania, Year: 2014, Spalten: ['num_patent_granted__field_life_sciences']\n",
      "Füge hinzu: Entity: Romania, Year: 2020, Spalten: ['num_patent_granted__field_life_sciences']\n",
      "Füge hinzu: Entity: Norway, Year: 2015, Spalten: ['num_patent_granted__field_life_sciences']\n",
      "Füge hinzu: Entity: Bulgaria, Year: 2016, Spalten: ['num_patent_granted__field_life_sciences']\n",
      "Füge hinzu: Entity: Bulgaria, Year: 2013, Spalten: ['num_patent_granted__field_life_sciences']\n",
      "\n",
      "health_filtered (Spalte: public_health_expenditure_share_gdp):\n",
      "Fehlende Kombinationen: 1\n",
      "Füge hinzu: Entity: Brazil, Year: 2020, Spalten: ['public_health_expenditure_share_gdp']\n",
      "\n",
      "Nach dem Auffüllen:\n",
      "\n",
      "ai_patents:\n",
      "Anzahl Zeilen: 312\n",
      "Unique entities: 39\n",
      "Unique years: [np.int64(2013), np.int64(2014), np.int64(2015), np.int64(2016), np.int64(2017), np.int64(2018), np.int64(2019), np.int64(2020)]\n",
      "Spalten: ['entities', 'years', 'num_patent_granted__field_life_sciences']\n",
      "\n",
      "Beispiel einer aufgefüllten Zeile:\n",
      "    entities  years  num_patent_granted__field_life_sciences\n",
      "0  Argentina   2013                                      0.0\n",
      "\n",
      "rd_gdp:\n",
      "Anzahl Zeilen: 312\n",
      "Unique entities: 39\n",
      "Unique years: [np.int64(2013), np.int64(2014), np.int64(2015), np.int64(2016), np.int64(2017), np.int64(2018), np.int64(2019), np.int64(2020)]\n",
      "Spalten: ['entities', 'years', 'research_spending_gdp']\n",
      "\n",
      "health:\n",
      "Anzahl Zeilen: 312\n",
      "Unique entities: 39\n",
      "Unique years: [np.int64(2013), np.int64(2014), np.int64(2015), np.int64(2016), np.int64(2017), np.int64(2018), np.int64(2019), np.int64(2020)]\n",
      "Spalten: ['entities', 'years', 'public_health_expenditure_share_gdp']\n",
      "\n",
      "Beispiel einer aufgefüllten Zeile:\n",
      "    entities  years  public_health_expenditure_share_gdp\n",
      "311   Brazil   2020                                  0.0\n",
      "\n",
      "median_age:\n",
      "Anzahl Zeilen: 312\n",
      "Unique entities: 39\n",
      "Unique years: [np.int64(2013), np.int64(2014), np.int64(2015), np.int64(2016), np.int64(2017), np.int64(2018), np.int64(2019), np.int64(2020)]\n",
      "Spalten: ['entities', 'years', 'median_age__sex_all__age_all__variant_estimates', 'median_age__sex_all__age_all__variant_medium']\n",
      "\n",
      "dependency:\n",
      "Anzahl Zeilen: 312\n",
      "Unique entities: 39\n",
      "Unique years: [np.int64(2013), np.int64(2014), np.int64(2015), np.int64(2016), np.int64(2017), np.int64(2018), np.int64(2019), np.int64(2020)]\n",
      "Spalten: ['entities', 'years', 'dependency_ratio__sex_all__age_old__variant_estimates', 'dependency_ratio__sex_all__age_youth__variant_estimates']\n"
     ]
    }
   ],
   "source": [
    "# Erstelle alle möglichen Entity-Jahr-Kombinationen\n",
    "years = list(range(2013, 2021))\n",
    "all_combinations = [(entity, year) for entity in best_entities for year in years]\n",
    "\n",
    "# Funktion zum Auffüllen fehlender Kombinationen mit den richtigen Spalten\n",
    "def fill_missing_combinations(df, all_combinations, df_name):\n",
    "    # Aktuelle Kombinationen im DataFrame\n",
    "    current_combinations = set(zip(df['entities'], df['years']))\n",
    "    # Konvertiere all_combinations zu Set für Vergleich\n",
    "    all_combinations_set = set(all_combinations)\n",
    "    # Finde fehlende Kombinationen\n",
    "    missing = all_combinations_set - current_combinations\n",
    "    \n",
    "    if missing:\n",
    "        print(f\"\\n{df_name}:\")\n",
    "        print(f\"Fehlende Kombinationen: {len(missing)}\")\n",
    "        \n",
    "        # Erstelle neue Zeilen für fehlende Kombinationen\n",
    "        new_rows = []\n",
    "        for entity, year in missing:\n",
    "            new_row = {\n",
    "                'entities': entity,\n",
    "                'years': year\n",
    "            }\n",
    "            \n",
    "            # Füge die spezifischen Spalten für jeden DataFrame mit 0.0 hinzu\n",
    "            value_columns = [col for col in df.columns if col not in ['entities', 'years']]\n",
    "            for col in value_columns:\n",
    "                new_row[col] = 0.0\n",
    "                \n",
    "            new_rows.append(new_row)\n",
    "            print(f\"Füge hinzu: Entity: {entity}, Year: {year}, Spalten: {value_columns}\")\n",
    "        \n",
    "        # Füge die neuen Zeilen zum DataFrame hinzu\n",
    "        df_filled = pd.concat([df, pd.DataFrame(new_rows)], ignore_index=True)\n",
    "        return df_filled\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Fülle die fehlenden Kombinationen für jeden DataFrame\n",
    "ai_patents_filled = fill_missing_combinations(\n",
    "    ai_patents_filtered, \n",
    "    all_combinations, \n",
    "    \"ai_patents_filtered (Spalte: num_patent_granted__field_life_sciences)\"\n",
    ")\n",
    "\n",
    "rd_gdp_filled = fill_missing_combinations(\n",
    "    rd_gdp_filtered, \n",
    "    all_combinations, \n",
    "    \"rd_gdp_filtered (Spalte: research_spending_gdp)\"\n",
    ")\n",
    "\n",
    "health_filled = fill_missing_combinations(\n",
    "    health_filtered, \n",
    "    all_combinations, \n",
    "    \"health_filtered (Spalte: public_health_expenditure_share_gdp)\"\n",
    ")\n",
    "\n",
    "median_age_filled = fill_missing_combinations(\n",
    "    median_age_filtered, \n",
    "    all_combinations, \n",
    "    \"median_age_filtered (Spalte: median_age__sex_all__age_all__variant_estimates)\"\n",
    ")\n",
    "\n",
    "dependency_filled = fill_missing_combinations(\n",
    "    dependency_filtered, \n",
    "    all_combinations, \n",
    "    \"dependency_filtered (Spalten: dependency_ratio__sex_all__age_old__variant_estimates, dependency_ratio__sex_all__age_youth__variant_estimates)\"\n",
    ")\n",
    "\n",
    "# Überprüfe die Ergebnisse nach dem Auffüllen\n",
    "print(\"\\nNach dem Auffüllen:\")\n",
    "for name, df in [\n",
    "    ('ai_patents', ai_patents_filled),\n",
    "    ('rd_gdp', rd_gdp_filled),\n",
    "    ('health', health_filled),\n",
    "    ('median_age', median_age_filled),\n",
    "    ('dependency', dependency_filled)\n",
    "]:\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"Anzahl Zeilen: {len(df)}\")\n",
    "    print(f\"Unique entities: {df['entities'].nunique()}\")\n",
    "    print(f\"Unique years: {sorted(df['years'].unique())}\")\n",
    "    print(\"Spalten:\", df.columns.tolist())\n",
    "    \n",
    "    # Zeige ein Beispiel einer aufgefüllten Zeile\n",
    "    filled_example = df[df.iloc[:, 2:].eq(0).any(axis=1)].head(1)\n",
    "    if not filled_example.empty:\n",
    "        print(\"\\nBeispiel einer aufgefüllten Zeile:\")\n",
    "        print(filled_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zusammenführung & Validierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True])"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_patents_filtered['entities'].unique() == ai_patents_filled['entities'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(best_entities) == set(ai_patents_filled['entities'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Informationen zum zusammengeführten DataFrame:\n",
      "Anzahl Zeilen: 312\n",
      "Anzahl Spalten: 9\n",
      "\n",
      "Spaltennamen:\n",
      "['entities', 'years', 'num_patent_granted__field_life_sciences', 'research_spending_gdp', 'public_health_expenditure_share_gdp', 'median_age__sex_all__age_all__variant_estimates', 'median_age__sex_all__age_all__variant_medium', 'dependency_ratio__sex_all__age_old__variant_estimates', 'dependency_ratio__sex_all__age_youth__variant_estimates']\n",
      "\n",
      "Erste Zeilen des zusammengeführten DataFrames:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entities</th>\n",
       "      <th>years</th>\n",
       "      <th>num_patent_granted__field_life_sciences</th>\n",
       "      <th>research_spending_gdp</th>\n",
       "      <th>public_health_expenditure_share_gdp</th>\n",
       "      <th>median_age__sex_all__age_all__variant_estimates</th>\n",
       "      <th>median_age__sex_all__age_all__variant_medium</th>\n",
       "      <th>dependency_ratio__sex_all__age_old__variant_estimates</th>\n",
       "      <th>dependency_ratio__sex_all__age_youth__variant_estimates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>2013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.61849</td>\n",
       "      <td>6.264</td>\n",
       "      <td>29.492</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.786158</td>\n",
       "      <td>39.246693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.59396</td>\n",
       "      <td>6.361</td>\n",
       "      <td>29.677</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.980871</td>\n",
       "      <td>39.027992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.62262</td>\n",
       "      <td>6.853</td>\n",
       "      <td>29.861</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.196878</td>\n",
       "      <td>38.837350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.55815</td>\n",
       "      <td>5.619</td>\n",
       "      <td>30.051</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.409235</td>\n",
       "      <td>38.617672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.55631</td>\n",
       "      <td>6.644</td>\n",
       "      <td>30.258</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.615713</td>\n",
       "      <td>38.336770</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    entities  years  num_patent_granted__field_life_sciences  \\\n",
       "0  Argentina   2013                                      0.0   \n",
       "1  Argentina   2014                                      0.0   \n",
       "2  Argentina   2015                                      0.0   \n",
       "3  Argentina   2016                                      0.0   \n",
       "4  Argentina   2017                                      0.0   \n",
       "\n",
       "   research_spending_gdp  public_health_expenditure_share_gdp  \\\n",
       "0                0.61849                                6.264   \n",
       "1                0.59396                                6.361   \n",
       "2                0.62262                                6.853   \n",
       "3                0.55815                                5.619   \n",
       "4                0.55631                                6.644   \n",
       "\n",
       "   median_age__sex_all__age_all__variant_estimates  \\\n",
       "0                                           29.492   \n",
       "1                                           29.677   \n",
       "2                                           29.861   \n",
       "3                                           30.051   \n",
       "4                                           30.258   \n",
       "\n",
       "   median_age__sex_all__age_all__variant_medium  \\\n",
       "0                                           NaN   \n",
       "1                                           NaN   \n",
       "2                                           NaN   \n",
       "3                                           NaN   \n",
       "4                                           NaN   \n",
       "\n",
       "   dependency_ratio__sex_all__age_old__variant_estimates  \\\n",
       "0                                          16.786158       \n",
       "1                                          16.980871       \n",
       "2                                          17.196878       \n",
       "3                                          17.409235       \n",
       "4                                          17.615713       \n",
       "\n",
       "   dependency_ratio__sex_all__age_youth__variant_estimates  \n",
       "0                                          39.246693        \n",
       "1                                          39.027992        \n",
       "2                                          38.837350        \n",
       "3                                          38.617672        \n",
       "4                                          38.336770        "
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Schrittweises Zusammenführen aller DataFrames\n",
    "merged_df = ai_patents_filled.merge(\n",
    "    rd_gdp_filled,\n",
    "    on=['entities', 'years'],\n",
    "    how='outer'\n",
    ").merge(\n",
    "    health_filled,\n",
    "    on=['entities', 'years'],\n",
    "    how='outer'\n",
    ").merge(\n",
    "    median_age_filled,\n",
    "    on=['entities', 'years'],\n",
    "    how='outer'\n",
    ").merge(\n",
    "    dependency_filled,\n",
    "    on=['entities', 'years'],\n",
    "    how='outer'\n",
    ")\n",
    "\n",
    "# Überprüfe das Ergebnis\n",
    "print(\"Informationen zum zusammengeführten DataFrame:\")\n",
    "print(f\"Anzahl Zeilen: {len(merged_df)}\")\n",
    "print(f\"Anzahl Spalten: {len(merged_df.columns)}\")\n",
    "print(\"\\nSpaltennamen:\")\n",
    "print(merged_df.columns.tolist())\n",
    "\n",
    "# Zeige die ersten Zeilen\n",
    "print(\"\\nErste Zeilen des zusammengeführten DataFrames:\")\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spalte löschen\n",
    "merged_df = merged_df.drop('median_age__sex_all__age_all__variant_medium', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Anzahl fehlender Werte pro Spalte:\n",
      "entities                                                   0\n",
      "years                                                      0\n",
      "num_patent_granted__field_life_sciences                    0\n",
      "research_spending_gdp                                      0\n",
      "public_health_expenditure_share_gdp                        0\n",
      "median_age__sex_all__age_all__variant_estimates            0\n",
      "dependency_ratio__sex_all__age_old__variant_estimates      0\n",
      "dependency_ratio__sex_all__age_youth__variant_estimates    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# # Überprüfe auf fehlende Werte\n",
    "print(\"\\nAnzahl fehlender Werte pro Spalte:\")\n",
    "print(merged_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entities</th>\n",
       "      <th>years</th>\n",
       "      <th>num_patent_granted__field_life_sciences</th>\n",
       "      <th>research_spending_gdp</th>\n",
       "      <th>public_health_expenditure_share_gdp</th>\n",
       "      <th>median_age__sex_all__age_all__variant_estimates</th>\n",
       "      <th>dependency_ratio__sex_all__age_old__variant_estimates</th>\n",
       "      <th>dependency_ratio__sex_all__age_youth__variant_estimates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>United States</td>\n",
       "      <td>2013</td>\n",
       "      <td>298.0</td>\n",
       "      <td>2.70215</td>\n",
       "      <td>7.886</td>\n",
       "      <td>36.175</td>\n",
       "      <td>20.454966</td>\n",
       "      <td>29.016796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>United States</td>\n",
       "      <td>2014</td>\n",
       "      <td>325.0</td>\n",
       "      <td>2.71786</td>\n",
       "      <td>13.329</td>\n",
       "      <td>36.274</td>\n",
       "      <td>20.979565</td>\n",
       "      <td>28.951674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>United States</td>\n",
       "      <td>2015</td>\n",
       "      <td>488.0</td>\n",
       "      <td>2.78700</td>\n",
       "      <td>13.598</td>\n",
       "      <td>36.387</td>\n",
       "      <td>21.491934</td>\n",
       "      <td>28.860523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>United States</td>\n",
       "      <td>2016</td>\n",
       "      <td>693.0</td>\n",
       "      <td>2.85350</td>\n",
       "      <td>13.830</td>\n",
       "      <td>36.509</td>\n",
       "      <td>22.009900</td>\n",
       "      <td>28.751198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>United States</td>\n",
       "      <td>2017</td>\n",
       "      <td>989.0</td>\n",
       "      <td>2.90432</td>\n",
       "      <td>13.796</td>\n",
       "      <td>36.650</td>\n",
       "      <td>22.566190</td>\n",
       "      <td>28.642460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>United States</td>\n",
       "      <td>2018</td>\n",
       "      <td>1243.0</td>\n",
       "      <td>3.01010</td>\n",
       "      <td>13.694</td>\n",
       "      <td>36.818</td>\n",
       "      <td>23.169268</td>\n",
       "      <td>28.498007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>United States</td>\n",
       "      <td>2019</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>3.17049</td>\n",
       "      <td>13.694</td>\n",
       "      <td>37.002</td>\n",
       "      <td>23.821184</td>\n",
       "      <td>28.315298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>United States</td>\n",
       "      <td>2020</td>\n",
       "      <td>714.0</td>\n",
       "      <td>3.46777</td>\n",
       "      <td>15.694</td>\n",
       "      <td>37.226</td>\n",
       "      <td>24.496876</td>\n",
       "      <td>28.065603</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          entities  years  num_patent_granted__field_life_sciences  \\\n",
       "304  United States   2013                                    298.0   \n",
       "305  United States   2014                                    325.0   \n",
       "306  United States   2015                                    488.0   \n",
       "307  United States   2016                                    693.0   \n",
       "308  United States   2017                                    989.0   \n",
       "309  United States   2018                                   1243.0   \n",
       "310  United States   2019                                   1138.0   \n",
       "311  United States   2020                                    714.0   \n",
       "\n",
       "     research_spending_gdp  public_health_expenditure_share_gdp  \\\n",
       "304                2.70215                                7.886   \n",
       "305                2.71786                               13.329   \n",
       "306                2.78700                               13.598   \n",
       "307                2.85350                               13.830   \n",
       "308                2.90432                               13.796   \n",
       "309                3.01010                               13.694   \n",
       "310                3.17049                               13.694   \n",
       "311                3.46777                               15.694   \n",
       "\n",
       "     median_age__sex_all__age_all__variant_estimates  \\\n",
       "304                                           36.175   \n",
       "305                                           36.274   \n",
       "306                                           36.387   \n",
       "307                                           36.509   \n",
       "308                                           36.650   \n",
       "309                                           36.818   \n",
       "310                                           37.002   \n",
       "311                                           37.226   \n",
       "\n",
       "     dependency_ratio__sex_all__age_old__variant_estimates  \\\n",
       "304                                          20.454966       \n",
       "305                                          20.979565       \n",
       "306                                          21.491934       \n",
       "307                                          22.009900       \n",
       "308                                          22.566190       \n",
       "309                                          23.169268       \n",
       "310                                          23.821184       \n",
       "311                                          24.496876       \n",
       "\n",
       "     dependency_ratio__sex_all__age_youth__variant_estimates  \n",
       "304                                          29.016796        \n",
       "305                                          28.951674        \n",
       "306                                          28.860523        \n",
       "307                                          28.751198        \n",
       "308                                          28.642460        \n",
       "309                                          28.498007        \n",
       "310                                          28.315298        \n",
       "311                                          28.065603        "
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df[merged_df['entities'] == 'United States']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entities</th>\n",
       "      <th>years</th>\n",
       "      <th>num_patent_granted__field_life_sciences</th>\n",
       "      <th>research_spending_gdp</th>\n",
       "      <th>public_health_expenditure_share_gdp</th>\n",
       "      <th>median_age__sex_all__age_all__variant_estimates</th>\n",
       "      <th>dependency_ratio__sex_all__age_old__variant_estimates</th>\n",
       "      <th>dependency_ratio__sex_all__age_youth__variant_estimates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Croatia</td>\n",
       "      <td>2013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.79817</td>\n",
       "      <td>5.441</td>\n",
       "      <td>41.727</td>\n",
       "      <td>27.684350</td>\n",
       "      <td>22.198648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Croatia</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.77259</td>\n",
       "      <td>5.470</td>\n",
       "      <td>41.972</td>\n",
       "      <td>28.282400</td>\n",
       "      <td>22.110374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Croatia</td>\n",
       "      <td>2015</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.82816</td>\n",
       "      <td>5.516</td>\n",
       "      <td>42.307</td>\n",
       "      <td>29.061613</td>\n",
       "      <td>22.106478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Croatia</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.84995</td>\n",
       "      <td>5.537</td>\n",
       "      <td>42.709</td>\n",
       "      <td>29.881420</td>\n",
       "      <td>22.167770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Croatia</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.84727</td>\n",
       "      <td>5.483</td>\n",
       "      <td>43.169</td>\n",
       "      <td>30.829208</td>\n",
       "      <td>22.315840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Croatia</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.95125</td>\n",
       "      <td>5.522</td>\n",
       "      <td>43.610</td>\n",
       "      <td>31.904163</td>\n",
       "      <td>22.491531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Croatia</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.07963</td>\n",
       "      <td>5.559</td>\n",
       "      <td>43.952</td>\n",
       "      <td>32.941430</td>\n",
       "      <td>22.611000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Croatia</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.24261</td>\n",
       "      <td>6.492</td>\n",
       "      <td>44.228</td>\n",
       "      <td>33.901455</td>\n",
       "      <td>22.622560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   entities  years  num_patent_granted__field_life_sciences  \\\n",
       "64  Croatia   2013                                      0.0   \n",
       "65  Croatia   2014                                      0.0   \n",
       "66  Croatia   2015                                      1.0   \n",
       "67  Croatia   2016                                      0.0   \n",
       "68  Croatia   2017                                      0.0   \n",
       "69  Croatia   2018                                      0.0   \n",
       "70  Croatia   2019                                      0.0   \n",
       "71  Croatia   2020                                      0.0   \n",
       "\n",
       "    research_spending_gdp  public_health_expenditure_share_gdp  \\\n",
       "64                0.79817                                5.441   \n",
       "65                0.77259                                5.470   \n",
       "66                0.82816                                5.516   \n",
       "67                0.84995                                5.537   \n",
       "68                0.84727                                5.483   \n",
       "69                0.95125                                5.522   \n",
       "70                1.07963                                5.559   \n",
       "71                1.24261                                6.492   \n",
       "\n",
       "    median_age__sex_all__age_all__variant_estimates  \\\n",
       "64                                           41.727   \n",
       "65                                           41.972   \n",
       "66                                           42.307   \n",
       "67                                           42.709   \n",
       "68                                           43.169   \n",
       "69                                           43.610   \n",
       "70                                           43.952   \n",
       "71                                           44.228   \n",
       "\n",
       "    dependency_ratio__sex_all__age_old__variant_estimates  \\\n",
       "64                                          27.684350       \n",
       "65                                          28.282400       \n",
       "66                                          29.061613       \n",
       "67                                          29.881420       \n",
       "68                                          30.829208       \n",
       "69                                          31.904163       \n",
       "70                                          32.941430       \n",
       "71                                          33.901455       \n",
       "\n",
       "    dependency_ratio__sex_all__age_youth__variant_estimates  \n",
       "64                                          22.198648        \n",
       "65                                          22.110374        \n",
       "66                                          22.106478        \n",
       "67                                          22.167770        \n",
       "68                                          22.315840        \n",
       "69                                          22.491531        \n",
       "70                                          22.611000        \n",
       "71                                          22.622560        "
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df[merged_df['entities'] == 'Croatia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl Einträge pro Land:\n",
      "entities\n",
      "Argentina         8\n",
      "Romania           8\n",
      "Luxembourg        8\n",
      "Mexico            8\n",
      "Netherlands       8\n",
      "Norway            8\n",
      "Peru              8\n",
      "Poland            8\n",
      "Portugal          8\n",
      "Slovenia          8\n",
      "Japan             8\n",
      "South Africa      8\n",
      "South Korea       8\n",
      "Spain             8\n",
      "Sweden            8\n",
      "Turkey            8\n",
      "Ukraine           8\n",
      "United Kingdom    8\n",
      "Lithuania         8\n",
      "Italy             8\n",
      "Austria           8\n",
      "Czechia           8\n",
      "Belgium           8\n",
      "Brazil            8\n",
      "Bulgaria          8\n",
      "Canada            8\n",
      "Chile             8\n",
      "China             8\n",
      "Croatia           8\n",
      "Denmark           8\n",
      "Israel            8\n",
      "Finland           8\n",
      "France            8\n",
      "Germany           8\n",
      "Greece            8\n",
      "Hungary           8\n",
      "India             8\n",
      "Ireland           8\n",
      "United States     8\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Zähle die Häufigkeit jeder Entity\n",
    "entity_counts = merged_df['entities'].value_counts()\n",
    "\n",
    "# Zeige die Ergebnisse\n",
    "print(\"Anzahl Einträge pro Land:\")\n",
    "print(entity_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desktiptive Analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv('merged_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "# # Liste der numerischen Variablen (anpassen an deine Spaltennamen)\n",
    "# variablen = [\n",
    "#     'num_patent_granted__field_life_sciences', \n",
    "#     'research_spending_gdp', \n",
    "#     'public_health_expenditure_share_gdp', \n",
    "#     'median_age__sex_all__age_all__variant_estimates', \n",
    "#     'dependency_ratio__sex_all__age_old__variant_estimates', \n",
    "#     'dependency_ratio__sex_all__age_youth__variant_estimates'\n",
    "# ]\n",
    "\n",
    "# # Histogramme erstellen\n",
    "# for var in variablen:\n",
    "#     plt.figure(figsize=(6,4))\n",
    "#     sns.histplot(merged_df[var], kde=True)\n",
    "#     plt.title(f'Histogramm von {var}')\n",
    "#     plt.xlabel(var)\n",
    "#     plt.ylabel('Häufigkeit')\n",
    "#     plt.show()\n",
    "\n",
    "# # Boxplots erstellen (um Ausreißer sichtbar zu machen)\n",
    "# for var in variablen:\n",
    "#     plt.figure(figsize=(6,2))\n",
    "#     sns.boxplot(x=merged_df[var])\n",
    "#     plt.title(f'Boxplot von {var}')\n",
    "#     plt.xlabel(var)\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple lineare Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unabhängige Variablen\n",
    "**KI-Fortschritt in der Medizin**\n",
    "- https://ourworldindata.org/grapher/artificial-intelligence-granted-patents-by-industry\n",
    "- https://ourworldindata.org/grapher/research-spending-gdp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
